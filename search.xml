<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[见闻 第1期]]></title>
    <url>%2Fposts%2Fbdcf%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[树莓派部署记录]]></title>
    <url>%2Fposts%2F754e%2F</url>
    <content type="text"><![CDATA[记录一下新买的树莓派 4 的部署过程，包括系统安装、网络连接、基本配置、Xrdp、Docker、Shadowsocks、Frp、Node.js、RSSHub、Nginx、HTTPS 等内容。本文尽可能提供可以直接执行的 bash 命令，方便后续参考。 1. 系统安装下载地址：Raspbian 为了方便之后使用 Xrdp 远程连接，下载的版本是带桌面的： Windows 下写入系统可以使用 Win32 Disk Imager，注意设备不要选错了。 写入成功后，在盘符为 boot 的 TF 卡分区根目录下，创建一个名为 ssh 的空文件。新版的 Raspbian 默认不开启 ssh，需要通过这种方式手动开启。 将 TF 卡插入树莓派，连上网线和电源即可。 2. 网络连接如果有显示器，直接接入显示器执行 ifconfig 即可获得 ip 地址。没有显示器的情况下，需要先使用网线连接，然后在路由器上查看树莓派有线网卡的 ip 地址。 使用 SSH 登录树莓派，用户 pi，密码为 raspberry 1ssh pi@ip 使用 raspi-config 连接 WiFi 1sudo raspi-config 设置完成后，树莓派会重启。（之后便用不上网线了） 3. 基本配置别名登录 12345# vim ~/.ssh/configHost pi HostName pc.andiedie.cn Port 22 User pi 无密码登录 1ssh-copy-id pi 修改密码 1sudo raspi-config 使用国内镜像加速（清华大学开源软件镜像站） 1234567891011121314sudo mv /etc/apt/sources.list /etc/apt/sources.list.baksudo tee /etc/apt/sources.list &lt;&lt;-'EOF'deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contribdeb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contribEOFsudo mv /etc/apt/sources.list.d/raspi.list /etc/apt/sources.list.d/raspi.list.baksudo tee /etc/apt/sources.list.d/raspi.list &lt;&lt;-'EOF'deb http://mirrors.tuna.tsinghua.edu.cn/raspberrypi/ buster main uiEOFsudo apt update# 可选，升级所有依赖sudo apt upgrade -y 安装常用软件 1sudo apt install -y vim unzip 4. Xrdp 远程桌面1sudo apt install xrdp -y 打开 Windows 远程桌面，连接 ip:3389，用户密码留空。 连接成功后，再输入 pi 的账号和密码即可。 5. Docker12345678910111213141516171819202122232425curl -fsSL get.docker.com | sh -s -- --mirror Aliyun# 将当前用户加入 docker 用户组，避免 sudosudo usermod -aG docker $USER# 镜像加速 阿里、七牛云、DaoCloud、Azuresudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": [ "https://【注意替换】.mirror.aliyuncs.com", "https://reg-mirror.qiniu.com", "http://【注意替换】.m.daocloud.io", "https://dockerhub.azk8s.cn" ]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker# 安装 Docker Compose# 安装 Pythonsudo apt install -y python python-pip libffi-dev python-backports.ssl-match-hostname# Pip 镜像加速pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplesudo pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplesudo pip install docker-compose 6. Shadowsock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 安装sudo apt install -y shadowsocks# 配置sudo tee /etc/shadowsocks/config.json &lt;&lt;-'EOF'&#123; "server": "【注意替换】", "server_port": "【注意替换】", "local_address": "127.0.0.1", "local_port": "1080", "password": "【注意替换】", "method": "【注意替换】"&#125;EOF# 开机启动sudo tee /etc/systemd/system/sslocal.service &lt;&lt;-'EOF'[Unit] Description = ShadowSocks Client After = network.target [Service] Type = simple User = root ExecStart = sslocal -c /etc/shadowsocks/config.json[Install] WantedBy = multi-user.targetEOFsudo systemctl start sslocalsudo systemctl enable sslocal# 安装 polipo 将 socks 协议转为 httpsudo apt install -y polipo# 配置sudo tee /etc/polipo/config &lt;&lt;-'EOF'logSyslog = falselogFile = /var/log/polipo/polipo.logsocksParentProxy = "127.0.0.1:1080"socksProxyType = socks5proxyAddress = "127.0.0.1"proxyPort = 1088EOF# 开机启动sudo systemctl start poliposudo systemctl enable polipo# 代理 aliastee -a ~/.bashrc &lt;&lt;-'EOF'alias pon='export use_proxy="on" &amp;&amp; export http_proxy="http://127.0.0.1:1088/" &amp;&amp; export https_proxy=$http_proxy &amp;&amp; export ftp_proxy=$http_proxy &amp;&amp; export dns_proxy=$http_proxy &amp;&amp; export rsync_proxy=$http_proxy &amp;&amp; export no_proxy="localhost,127.0.0.1,localaddress,.localdomain.com"'alias poff='unset use_proxy &amp;&amp; unset http_proxy &amp;&amp; unset https_proxy &amp;&amp; unset ftp_proxy &amp;&amp; unset dns_proxy &amp;&amp; unset rsync_proxy &amp;&amp; unset no_proxy'EOFsource ~/.bashrc 7. Frp1234567891011121314151617181920212223242526272829303132333435363738394041# 开启代理pon# 下载wget https://github.com/fatedier/frp/releases/download/v0.29.0/frp_0.29.0_linux_arm.tar.gz# 关闭代理poff# 解压tar -xzf frp_0.29.0_linux_arm.tar.gz# 移动到合适的位置sudo mkdir -p /usr/sbin/frpsudo mv frp_0.29.0_linux_arm/frps /usr/sbin/frpsudo mkdir -p /etc/frp# 清理rm -f frp_0.29.0_linux_arm.tar.gzrm -rf frp_0.29.0_linux_arm# 配置sudo tee /etc/frp/frps.ini &lt;&lt;-'EOF'[common]bind_port = 7000dashboard_port = 7500dashboard_user = 【注意替换】dashboard_pwd = 【注意替换】token = 【注意替换】EOF# 开机自启sudo tee /etc/systemd/system/frps.service &lt;&lt;-'EOF'[Unit]Description=FRP Server DaemonAfter=network.targetWants=network.target[Service]Type=simpleExecStart=/usr/sbin/frp/frps -c /etc/frp/frps.iniRestart=always[Install]WantedBy=multi-user.targetEOFsudo systemctl start frpssudo systemctl enable frps 8. Node.js12345678sudo apt install -y nodejs npmsudo npm i -g npm --registry=https://registry.npm.taobao.orgsudo npm i -g nrm --registry=https://registry.npm.taobao.orgnrm use cnpmsudo npm i -g yarn nponsudo n ltspoff 9. RSSHub1234567891011121314151617181920212223cd /home/pi/Desktoppongit clone https://github.com/DIYgod/RSSHub.gitpoffcd RSSHub/yarn# 开机启动sudo tee /etc/systemd/system/rsshub.service &lt;&lt;-'EOF'[Unit] Description = RSSHubAfter = network.target [Service] Type = simple ExecStart = /bin/bash -c 'PROXY_PROTOCOL=socks PROXY_HOST=127.0.0.1 PROXY_PORT=1080 PROXY_URL_REGEX="instagram|twitter" TWITTER_CONSUMER_KEY=【注意替换】 TWITTER_CONSUMER_SECRET=【注意替换】 GITHUB_ACCESS_TOKEN=【注意替换】 yarn --cwd /home/pi/Desktop/RSSHub start'[Install] WantedBy = multi-user.targetEOFsudo systemctl start rsshubsudo systemctl enable rsshub 10. Nginx123456789101112131415161718192021222324252627282930313233343536# 安装 Certbotsudo apt install -y certbot# 安装 nginxsudo apt install -y nginx# 打开 https://nginxconfig.io/?0.domain=rss.andiedie.cn&amp;0.document_root=&amp;0.redirect=false&amp;0.email=zchangan@163.com&amp;0.php=false&amp;0.proxy&amp;0.proxy_pass=http:%2F%2F127.0.0.1:1200&amp;0.root=false# 下载 zip 文件，放到 /etc/nginx 目录下cd /etc/nginx# 解压sudo unzip -o nginxconfig.io-rss.andiedie.cn.zip# 生成 Diffie-Hellman 参数sudo openssl dhparam -out /etc/nginx/dhparam.pem 2048# 获得泛域名证书（renew 也是这样）sudo certbot certonly --preferred-challenges dns --manual -d *.andiedie.cn --email zchangan@163.com --agree-tos --force-renewal --server https://acme-v02.api.letsencrypt.org/directory# 根据要求给 DNS 添加 TXT 记录# 还需要添加 CAA 记录，推荐 cloudflare# CAA andiedie.cn 0 issue ";"# 添加 SSL 证书通用配置sudo tee /etc/nginx/ssl.conf &lt;&lt;-'EOF'ssl_certificate /etc/letsencrypt/live/andiedie.cn/fullchain.pem;ssl_certificate_key /etc/letsencrypt/live/andiedie.cn/privkey.pem;ssl_trusted_certificate /etc/letsencrypt/live/andiedie.cn/chain.pem;EOF# 将 SSL 三连 改为# include ssl.conf;sudo vim /etc/nginx/sites-available/frp.andiedie.cn.confsudo vim /etc/nginx/sites-available/frp.andiedie.cn.conf# 启动sudo nginx -t &amp;&amp; sudo systemctl reload nginxsudo systemctl enable nginx]]></content>
  </entry>
  <entry>
    <title><![CDATA[不靠谱租房指南]]></title>
    <url>%2Fposts%2Fd968%2F</url>
    <content type="text"><![CDATA[最近我和女友都准备毕业工作，于是分别在广州和深圳都租了房子。这篇博客记录我在租房前后积累的一些租房、看房、签合同相关的经验，以备不时之需。 1. 获取房源信息租房的第一步就是获取房源，现在途径有很多： 链家、自如、贝壳、安居客等在线平台 魔方公寓、泊寓等精装修房源 线下中介 58、赶集之类的信息发布网站 豆瓣小组、知乎等小众平台 扫街 接下来从获取难度、可靠程度、价格等方面，简单介绍一下每一种房源。满分五颗星，星星越多，获取难度越大，可靠程度越高，价格越低。 1.1. 租房信息来源比较1.1.1. 线上租房平台难度：★☆☆☆☆ 可靠：★★★☆☆ 价格：★★★☆☆ 一般人最容易接触到的就是各类线上的租房平台，例如链家、贝壳、安居客、自如等。从这类平台上获取信息非常容易，但是一些不靠谱的平台上各类租房信息也是鱼龙混杂。比如安居客上，会出现非常多低价房源，价格低到难以置信，但是房间图片却非常精美。一般这种房源是为了吸引租客看房，如果对方比较善良，那顶多就是以“房间刚刚租了”之类的理由带租客去看一些贵的房源，对方狡诈一点的话还会通过收取看房费骗租客的钱。 我自用了很多平台，最后还是比较推荐贝壳（贝壳的财务看到了请给我打钱谢谢）。主要是因为贝壳爬了很多别的平台的信息（安居客前段时间就因为这个告了贝壳），可以一次搞定多个平台的搜索；贝壳上的低价不靠谱房源在我使用的过程中也出现得比较少；最推荐的理由是贝壳可以筛选公司附近几公里内的房源（无法想象为什么这么基础的功能别家居然没有）。 1.1.2. 精装修公寓难度：★☆☆☆☆ 可靠：★★★★★ 价格：★☆☆☆☆ 这类诸如魔方、泊寓之类的精装修公寓，也可以在贝壳、安居客之类的平台上看到，优点是非常可靠，家电齐全、安保完善、周边购物或交通比较便利，且一般都有桌游室、台球桌、健身房之类的公共空间。缺点同样非常明显，就是贵，不仅房租贵、管理费贵，一般用的是商用水电，所以每月水电费也贵。 1.1.3. 线下中介难度：★★☆☆☆ 可靠：★★★☆☆ 价格：★★★☆☆ 最传统的就是找一些线下卖二手房和租房的中介，就是那种店面玻璃上贴满了房源信息的店。其实绝大多数个人房源，特别是房间多的套房，房东都没闲功夫自己找人出租，这类中介就负责从房东手里接管房子的出租权，然后租给租客。 获取难度略高，因为需要线下跑店面，但是综合来说也相当省时省力，毕竟你只需要告诉中介你的目标房型、价格、位置等信息，他会帮你筛选。缺点也有，一个是需要中介费，一般是一个月或半月的房租作为中介费；另外就是中介手上的房子可能还是套房居多，个人租单间的话不太合适。 1.1.4. 信息发布网站难度：★★☆☆☆ 可靠：★☆☆☆☆ 价格：★★★☆☆ 类似 58 同城、赶集网之类的信息发布网站上一般也会有租房信息，不过分为两类：一类是房东直租，这类房子免中介费、租金不高，就是比较少遇到；另一类就是中介发布的信息，线下中介的主要宣传方式就是这类信息发布网站。不过也不要因为对方是中介就有什么避讳，勤在 58 上发信息、甚至买精选的中介，一般都是用心做的，相对还是比较靠谱的。 1.1.5. 小众平台难度：★★★★☆ 可靠：★★★★☆ 价格：★★★☆☆ 豆瓣小组、知乎甚至某些神秘的 QQ、微信群里面也可以淘到不少优质的租房信息。这些租房信息真实度高，价格也合理，主要的缺点就是这类小众平台缺乏针对租房的筛选功能，因此获取对口的租房信息其实非常耗费时间精力。 1.1.6. 扫街难度：★★★★★ 可靠：★★★★☆ 价格：★★★★☆ 最硬核的租房方式就是扫街，到租房地附近的小区大门、电线杆之类的地方看房东贴出来的租房广告，或者问门卫大叔、居委会大妈之类的角色，他们一般都知道哪家要租房。直接联系到房东，价格便宜、信息真实，就是要找到这样的房子是要靠步数和运气的。 1.2. 综合推荐最后还是推荐直接在链家、贝壳之类的地方直接看房源，说实话省时省心且相对靠谱。不过在平台上挑房子也是有要注意的地方，没必要拘泥于同一个小区内的不同装修的房子，或者是同一个中介手上区别不大的房子，要多看不同的小区、多看不同中介手上的房子，因为事后看房的事后，中介会领你看同一个小区和附近的所有房子。线上只需要关注位置、交通等关键部分，细节交给线下看房。 2. 看房2.1. 约看房约房东或者中介看房，如果是女生的话一定要找人同行，独自看房非常危险。一天可以约三个左右的中介，早中晚各一个。看房速度其实很快，一个区域内的房间一个小时内就能全部看完。用更少的时间，看更多的小区。 2.2. 看房列表跟中介进了房间，就要开始注意以下内容： 安全：如果是女生独自看房，注意一定不要关门，方便随时逃跑； 隔音：用手敲一敲墙壁是不是隔音好的承重墙、门窗缝隙会不会过大。有条件的话还可以打开水龙头、花洒、冲厕所、抽油烟机等方法听一听声音是否过大； 晾晒：房间是否有足够的晾晒空间比如阳台，是否有楼顶等公共晾晒空间； 网络：打开手机，看网络信号，有条件的话三个运营商的都看一下；询问是否有自带宽带、资费如何、是否可以自拉网线等； 损坏：门窗是否能够正常开馆、房间内的墙面插座是否有效、厕所冲水是否有效等； 电器：空调、冰箱、洗衣机、热水器等电器的新旧情况，另外一定要注意有些电器是否是需要“扫码付费使用”； 漏水：洗手池、浴室、测试、阳台是否能正常漏水，房间内的管道、阳台外的管道是否会渗水； 水电：商用水电还是民用水电； 周边：是否有 24 小时便利店、菜市场、超市； 管理：管理费多少钱，是否包维修； 宠物：是否可以养宠物 3. 签合同3.1 签合同之前签合同之前有很多需要注意的地方： 如何支付房租、如果延迟交房租如何处理 水电、网络、天然气费用如何缴纳 提早搬离如何处理 房屋改造的限制和手续，比如更换灯具、刷墙、粘贴、打孔等 如何续约 押金多少，扣押金的条件 切勿随意缴纳定金 3.2. 合同本身仔细阅读合同条款，特别注意： 租房人和承租人信息是否正确 租期、房间号、房租、押金是否正确 条款是否与口头不一致 另外有一些关于租房合同的常识： 《 合同法 》 第 215 条规定：租赁期限六个月以上的，应当采用书面形式。当事人未采用书面形式的，视为不定期租赁。（不定期租赁时，双方都可以随时单方面接触租赁关系，如果是出租人解除，则需要给与承租人合理的搬迁期限） 《 房地产管理法 》 第 54 条规定：房屋租赁，出租人和承租人应当签订书面租赁合同，并向房产管理部分登记备案。但是登记备案不是租赁合同生效的必要条件，因此也可以不登记。 《 商品房屋租赁管理办法 》 第八条：出租住房的，应当以原设计的房间为最小出租单位，人均租住建筑面积不得低于当地人民政府规定的最低标准。厨房、卫生间、阳台和地下储藏室不得出租供人员居住。因此注意，将房间分割后进行出租的行为，是违法的。 3.3. 签完合同签完合同时需要注意： 保留合同、房东身份证明（身份证复印件）、房屋所有权证书（房产证复印件）、租房授权委托书（如果对方是中介则需要） 拍照记录房间内的所有细节，包括现有的破损情况、家具和家电的新旧情况等 记录当前水电表读数（方便日后核对） 保留押金、租金、中介费的收据 保留家具清单 保留房东的通讯地址 以上就是我个人的一些租房经验，希望有所帮助。祝大家都能租到满意的房子。]]></content>
  </entry>
  <entry>
    <title><![CDATA[TVPause : 接打电话时自动暂停电视]]></title>
    <url>%2Fposts%2Fcb98%2F</url>
    <content type="text"><![CDATA[最近家里有个小的需求，就是希望在接打电话的时候能够自动暂停电视节目。于是我就写了一个简单的工具，这篇博客主要记录实现的过程、遇到的问题以及一些小的心得。开源地址：TVPause 1. 需求也许有人会奇怪为什么会有“接打电话的时候自动暂停电视节目”这种伪需求，直接按个遥控器上静音或者暂停按钮不就行了吗？事情并没有那么简单。 首先，家里有一个习惯是，吃饭的时候看电视，如果吃饭的时候来电话，得先放下碗筷，静音/暂停电视，然后接听电话，步骤很多 其次，爸爸做小本生意，晚上经常会有订货的电话，因此这个需求出现的频次很高 最后，家里用的是小米电视，小米电视遥控器，没有静音按钮！🤨 因此我决定着手解决这个问题，理想的状态时，一旦来电，如果正在播放点播节目，就直接暂停；如果正在收看电视直播，就静音。 不过后来发现，想要获取小米电视正在播放点播节目还是电视直播并不容易，于是就选择了一种“又不是不能用”的实现方法：一旦来电，模拟按下确认按钮（如果是点播节目会暂停，直播则无效果），并静音；电话结束后，再次模拟按下确认按钮（点播节目会继续，直播则无效果），恢复音量。 这样的好处是，实现简单。坏处是，模拟点击确认按钮这个过程不够可靠，会误触一些其他按钮。例如此时电视其实并没有在播放节目，而是在主界面待机，此时来电点击确认按钮的话，就会选中光标内容。 无伤大雅，只要使用上略加注意就行了，开发效率万岁。🎉 最终流程： 123接打电话 → 保存当前音量值 → 模拟点击确认 → 调整音量为 0电话结束 → 读取备份音量值 → 模拟点击确认 → 恢复备份音量 2. 小米电视协议分析家里的手机都没有红外接口，且红外对物理要求太高，所以我直接放弃了红外这条路。下一条路就是分析小米电视的 APP “小米投屏神器” 的协议。 2.1. 初战 HTTP 协议最容易想到和分析的就是 HTTP 协议，按照 移动设备抓包 这篇博客中的介绍，使用 Charles 抓包，结果如下： 服务发现 打开 APP 第一步必然是先找到小米电视的服务地址，这里发现了一条功能类似的 API，提供了小米电视非常详细的信息。但是这个 API 虽然使用的是 HTTPS，但是证书确实私自签发的，直接请求会报错： 且里面有一些参数例如，deviceid 和 key 还暂时不知道来源。 另外最重要的是，这个 API 是向公网请求的设备信息，而服务发现应该是在局域网就能完成的事情，所以暂时放弃该 API。 获取音量在进入手机遥控器的时候，手机会发起一个获取音量的请求： 这个 API 就非常友好： 向内网的小米电视发送请求 HTTP 协议 没有乱七八糟的参数 可以直接拿来用 设置音量在 APP 上调整音量有两个方式，一个是通过手机音量键步进调整，一个是使用 UI 上的拖动条直接一步到位。 步进调整的请求使用 Charles 无法获取，下面是拖动调整的 API： 这里的 API 和上面的获取音量的非常相似，有如下参数 action：setVolum 表示设置音量 volum：目标音量 ts：时间戳 sign：签名 问题就出在这个签名上，签名一般是将参数以某种顺序拼接后，附带盐值，然后使用 Hash 算法计算。这里不知道拼接顺序，也不知道是否有盐值，更不知道算法是什么，所以使用这个 API 非常困难。 失败接着发现包括步进调整音量、点击确认、上下左右等所有 APP 上的点按按键都无法使用 Charles 获取请求，很明显这里使用的不是 HTTP 请求，再加上之前服务发现和设置音量的 API 不可用，所以第一次挑战 HTTP API 失败。 2.2. TCP / UDP 协议既然 Charles 不行，那就上 Wireshark。按照 移动设备抓包 这篇博客中介绍的，使用 Wireshark 监听 iPhone 上的数据包。 点击按钮开启 Wireshark，点击“确认”按钮后，拦截到数据包，适当过滤后： 两个包的内容分别为 其中，蓝色的部分就是 TCP 的数据字段。经过多次拦截和分析后，总结出的协议格式如下： 123450000 04 00 41 01 00 00 00 45 00 3a 01 00 00 00 00 020010 00 00 00 01 03 00 00 00 42 04 00 00 00 1c 05 000020 00 00 00 06 00 00 00 08 07 00 00 00 00 00 00 000030 00 08 00 00 00 00 00 00 00 00 0a ff ff ff ff 0b0040 00 00 03 01 0004 ~ 0007 是序号，每次发送 +1 0010 ~ 0013 每次按键时会发送两次几乎一模一样的 TCP 包，第一次该字段为 0， 第二次为 1。推测应该是按键状态，0 表示按下，1 表示松开。 0018 ~ 001f 是按键码，详见下表 其他位保持变即可 按键码表： 按键功能 按键码 电源 0x1a04000000740500 上 0x1304000000670500 下 0x14040000006c0500 左 0x1504000000690500 右 0x16040000006a0500 确认 0x42040000001c0500 主页 0x0304000000660500 返回 0x04040000009e0500 菜单 0x05040000008b0500 音量增 0x1804000000730500 音量减 0x1904000000720500 服务发现在使用 Wireshark 监听时发现，除了上述的 TCP 包用于发送指令，APP 还会在刚启动时使用 mDNS 协议寻找服务： 如上图，前 4 个包是 APP 刚启动时，向所有网段广播寻找 _rc._tcp 类型的服务。之后小米电视收到广播，回复了服务的端口和地址，并附带了小米电视的详细信息。 在命令行可以使用下列命令模拟： 1234# 搜索服务dns-sd -B _rc._tcp local# 获取服务相信信息dns-sd -L 客厅的小米盒子 _rc._tcp. 2.3. 再战 HTTP 协议其实到之前的步骤已经可以实现整个应用了： 123接打电话 → 通过 mDNS 协议搜索小米电视 → 通过 HTTP 协议获取当前音量 → 保存当前音量 → 通过 TCP 协议按下确认键并调节音量至0电话结束 → 通过 mDNS 协议搜索小米电视 → 通过 HTTP 协议获取当前音量 → 读取存档音量 → 通过 TCP 协议按下确认键并恢复音量 实际上我也实现另一个这样的版本，但是遇到了几个问题： 在使用 TCP 连接上小米电视后，第一次连接总是会被服务端关闭 Socket。原因不明，应该不是我的实现问题，因为 APP 也会出现这个问题。 如果当前音量是 50，那么调整音量为 0 需要至少 50 个 TCP 包。当然理论上是 100 个，包括 50 次音量下键每次两个包，但是测试发现只发送第一个包也没什么问题，因此是 50 个。这样速度慢，并且非常不稳定。 上述两个问题出现一个还好解决，但是总是一起出现，比如调节音量的包发了几个，Socket 被关了，处理起来非常麻烦。 所以我放弃了这个方案，决定再战一次 HTTP 协议，毕竟有个 setVolum 的 API 实在非常诱人。 3. 反编译无法使用 setVolum 的原因是不知道如何计算 sign，既然如此，就直接反编译 APP 看看，这个签名究竟是怎么算出来的。关于反编译的简易教程可以查看这篇博客。 3.1. 查看源码让我们列一个任务表，更加清晰地追踪源码： 任务 完成 计算签名的输入 计算签名的算法 分析设置音量的函数使用 jd-gui 查看投屏神器的源码，找到设置音量的对应函数： 12345678910// com.xiaomi.mitv.phone.tvassistant.b.a.a(int) : voidpublic void a(int paramInt)&#123; String str1 = String.valueOf(System.currentTimeMillis()); String str2 = a(String.valueOf(paramInt), this.b, str1); new c(this.d, String.format("http://%s:6095/general?action=setVolum&amp;volum=%d&amp;ts=%s&amp;sign=%s", new Object[] &#123; this.a, Integer.valueOf(paramInt), str1, str2 &#125;), new c.a() &#123; public void a(int paramAnonymousInt, String paramAnonymousString) &#123;&#125; &#125;).d();&#125; 可以看到，第 6 行发出了请求，根据 String.format可以得知一些变量对应的信息： paramInt： 目标音量值 str1：当前时间 str2：签名 显然，如何计算 str2 是最令人感兴趣的部分。 来到第 5 行，发现 str2 使用函数 a 计算，函数 a 就是计算签名的函数。 函数 a 的参数分别为： String.valueOf(paramInt)：目标音量 this.b：暂时不明 str1：当前时间 任务 完成 计算签名的输入 ❓ 计算签名的算法 ❓ this.b 是什么 ❓ 分析签名的输入查看函数 a 的逻辑： 12345// com.xiaomi.mitv.phone.tvassistant.b.a.a(String, String, String) : Stringprivate String a(String paramString1, String paramString2, String paramString3)&#123; return g.a("mitvsignsalt" + paramString1 + paramString2 + paramString3.substring(paramString3.length() - 5));&#125; 很明显，这就是计算 sign 的函数，计算逻辑如下： 将盐值 mitvsignsalt、目标音量 paramString1、paramString2（即this.b）和当前时间 paramString3 拼接在一起 调用函数 g.a 计算 至此，我们搞懂了计算签名的输入，就是上述的字符串拼接。 任务 完成 计算签名的输入 ✅ 计算签名的算法 ❓ this.b 是什么 ❓ 分析签名的算法让我们看看 g.a 干了什么： 12345678// com.xiaomi.mitv.socialtv.common.e.g.a(String) : Stringpublic static String a(String paramString)&#123; if (paramString == null) &#123;&#125; for (paramString = "";; paramString = a(paramString.getBytes())) &#123; return paramString; &#125;&#125; g.a 调用了一个重载的函数： 12345678910111213141516171819202122// com.xiaomi.mitv.socialtv.common.e.g.a(byte[]) : Stringpublic static String a(byte[] paramArrayOfByte)&#123; if (paramArrayOfByte == null) &#123; paramArrayOfByte = ""; &#125; for (;;) &#123; return paramArrayOfByte; try &#123; MessageDigest localMessageDigest = MessageDigest.getInstance("MD5"); localMessageDigest.reset(); localMessageDigest.update(paramArrayOfByte); paramArrayOfByte = e.a(localMessageDigest.digest()); &#125; catch (Exception paramArrayOfByte) &#123; paramArrayOfByte = ""; &#125; &#125;&#125; 很明显了，签名的算法是 MD5 任务 完成 计算签名的输入 ✅ 计算签名的算法 ✅ this.b 是什么 ❓ this.b 是什么只要搞清楚 this.b 是什么，我们就可以计算签名了。而且根据经验，它很可能是一个 key。由服务端（小米电视）和客户端（手机 APP）共同拥有。 然而很遗憾，以我的功力，没能够在代码里面找到 this.b 的来源，所以我换了一个新方法。 3.2. 重编译 APP既然没办法直接把 this.b 是什么看出来，我就想着干脆用日志把它的值输出出来，看看有什么猫腻。 这就涉及到反编译 APP，修改源码，重新打包和签名，具体过程可以查看这篇博客。 唯一修改的文件 smali/com/xiaomi/mitv/phone/tvassistant/b/a.smali： 123456789101112131415161718192021222324252627282930313233343536373839404142.method public a(I)V # 额外定义 4 个寄存器用于存储 TAG .locals 12 .prologue .line 55 # 设置初始化TAG const-string v8, "AndiedieHack.currentTimeMillis" const-string v9, "AndiedieHack.param" const-string v10, "AndiedieHack.b" const-string v11, "AndiedieHack.result" invoke-static &#123;&#125;, Ljava/lang/System;→currentTimeMillis()J move-result-wide v0 invoke-static &#123;v0, v1&#125;, Ljava/lang/String;→valueOf(J)Ljava/lang/String; move-result-object v0 # 第一个 Log，输出 v0 的值，即系统当前时间 invoke-static &#123;v8, v0&#125;, Landroid/util/Log;→d(Ljava/lang/String;Ljava/lang/String;)I .line 57 invoke-static &#123;p1&#125;, Ljava/lang/String;→valueOf(I)Ljava/lang/String; move-result-object v1 # 第二个 Log，输出 v1 的值，即目标音量 invoke-static &#123;v9, v1&#125;, Landroid/util/Log;→d(Ljava/lang/String;Ljava/lang/String;)I iget-object v2, p0, Lcom/xiaomi/mitv/phone/tvassistant/b/a;→b:Ljava/lang/String; # 第三个 Log，输出 v2 的值，即 this.b invoke-static &#123;v10, v2&#125;, Landroid/util/Log;→d(Ljava/lang/String;Ljava/lang/String;)I invoke-direct &#123;p0, v1, v2, v0&#125;, Lcom/xiaomi/mitv/phone/tvassistant/b/a;→a(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; move-result-object v1 # 第四个 Log，输出 v1 的值，即签名结果 invoke-static &#123;v11, v1&#125;, Landroid/util/Log;→d(Ljava/lang/String;Ljava/lang/String;)I 运行修改后的 APP，尝试修改音量，出现以下日志： 这个 this.b 的值是 3c:bd:3e:84:35:31 乍一看就是一个 mac 地址，很有可能就是小米电视的 mac 地址，于是我兴奋地打开路由器界面查询： 不一样🤕！！！ 正当我心灰意冷之时，我猛然发现，这个 mac 地址和刚刚 mDNS 里面获取的 mac 地址一模一样： 之后才发现，3c:bd:3e:84:35:31 是小米电视的以太网口的 mac 地址。 也就是说，this.b 的值可以通过 mDNS 获取。 任务 完成 计算签名的输入 ✅ 计算签名的算法 ✅ this.b 是什么 ✅ 3.3. 验证接下来对签名算法进行验证： OK，通过 4. 实现经过上面的折腾，最终的方案定为： 12345678910111213接打电话 ↓通过 mDNS 协议搜索小米电视 ┣→ 通过 TCP 协议按下确认键 ┗→ 通过 HTTP 协议获取当前音量 ┣→ 保存当前音量 ┗→ 通过 HTTP 设置音量为 0电话结束 ↓通过 mDNS 协议搜索小米电视 ┣→ 通过 TCP 协议按下确认键 ┗→ 读取保存音量 → 通过 HTTP 恢复音量 4.1. mDNS 实现利用 mDNS 获取小米电视信息，这里借助 Android 提供的 NsdManager 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546val mNsdManager = getSystemService(Context.NSD_SERVICE) as NsdManagerval mDiscoveryListener = object : NsdManager.DiscoveryListener &#123; val listen = this override fun onServiceFound(serviceInfo: NsdServiceInfo?) &#123; Log.d(TAG, "ServiceFound: $serviceInfo") // 发现服务后，获取服务详细信息 mNsdManager.resolveService(serviceInfo, object: NsdManager.ResolveListener &#123; override fun onResolveFailed(serviceInfo: NsdServiceInfo?, errorCode: Int) &#123; Log.e(TAG, "Resolve failed: $errorCode") &#125; override fun onServiceResolved(serviceInfo: NsdServiceInfo?) &#123; Log.d(TAG, "Resolve Succeeded. $serviceInfo") if (serviceInfo == null) return // ！！服务详细信息！！ serviceInfo mNsdManager.stopServiceDiscovery(listen) &#125; &#125;) &#125; override fun onStopDiscoveryFailed(serviceType: String?, errorCode: Int) &#123; Log.e(TAG, "Stop DNS-SD discovery failed: Error code:$errorCode") mNsdManager.stopServiceDiscovery(this) &#125; override fun onStartDiscoveryFailed(serviceType: String?, errorCode: Int) &#123; Log.e(TAG, "Start DNS-SD discovery failed: Error code:$errorCode") mNsdManager.stopServiceDiscovery(this) &#125; override fun onServiceLost(serviceInfo: NsdServiceInfo?) &#123; Log.e(TAG, "DNS-SD service lost: $serviceInfo") &#125; override fun onDiscoveryStarted(serviceType: String?) &#123; Log.d(TAG, "DNS-SD discovery started") &#125; override fun onDiscoveryStopped(serviceType: String?) &#123; Log.d(TAG, "DNS-SD discovery stopped: $serviceType") &#125;&#125;// 注意服务类型是 _rc._tcpmNsdManager.discoverServices("_rc._tcp", NsdManager.PROTOCOL_DNS_SD, mDiscoveryListener) 4.2. Socket 实现借助 Socket 发送 TCP 包，实现暂停： 12345678910val CONFIRM_BYTES = byteArrayOf(0x04, 0x00, 0x41, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x3a, 0x01, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x42, 0x04, 0x00, 0x00, 0x00, 0x1c, 0x05, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00, 0x08, 0x07, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x03, 0x01)val socket = Socket(serviceInfo.host, serviceInfo.port)val oStream = socket.getOutputStream()val press = CONFIRM_BYTESval up = CONFIRM_BYTES.copyOf()up[0x13] = 0x01oStream.write(press)oStream.write(up)oStream.flush() 4.3. 监听电话状态添加权限 1&lt;uses-permission android:name="android.permission.READ_PHONE_STATE" /&gt; 注意这个权限必须运行时请求： 123456789101112131415161718192021222324252627282930313233343536373839404142private const val PERMISSIONS_REQUEST = 852private fun hasPermissions(permissions: List&lt;String&gt;): Boolean &#123; for (permission in permissions) &#123; if (ActivityCompat.checkSelfPermission(this, permission) != PackageManager.PERMISSION_GRANTED) &#123; return false &#125; &#125; return true&#125;private fun checkPermissions() &#123; val permissions = mutableListOf&lt;String&gt;(Manifest.permission.READ_PHONE_STATE) if (!hasPermissions(permissions)) &#123; Log.d(TAG, "Permissions missing") ActivityCompat.requestPermissions(this, permissions.toTypedArray(), PERMISSIONS_REQUEST) &#125; else &#123; Log.d(TAG, "Permissions granted") permission = true &#125;&#125;override fun onRequestPermissionsResult(requestCode: Int, permissions: Array&lt;out String&gt;, grantResults: IntArray) &#123; if (grantResults.isEmpty()) return when (requestCode) &#123; PERMISSIONS_REQUEST -&gt; &#123; var flag = true for (result in grantResults) &#123; if (result != PackageManager.PERMISSION_GRANTED) &#123; flag = false break &#125; &#125; permission = if (flag) &#123; Log.d(TAG, "Request permissions success") true &#125; else &#123; Log.d(TAG, "Request permissions failed") false &#125; &#125; &#125;&#125; 服务实现： 12345678910111213141516171819202122private val phoneStateReceiver = object : BroadcastReceiver() &#123; private var lastIdle = true override fun onReceive(context: Context?, intent: Intent?) &#123; if (context == null || intent == null) return when (intent.action) &#123; TelephonyManager.ACTION_PHONE_STATE_CHANGED -&gt; &#123; val tManager = context.getSystemService(TELEPHONY_SERVICE) as TelephonyManager if (tManager.callState == TelephonyManager.CALL_STATE_IDLE) &#123; lastIdle = true // 电话结束 &#125; else if (lastIdle) &#123; lastIdle = false // 接打电话 &#125; &#125; &#125; &#125;&#125;private fun register() &#123; this.registerReceiver(phoneStateReceiver, IntentFilter(TelephonyManager.ACTION_PHONE_STATE_CHANGED))&#125; 5. 坑5.1. 刚连接 WiFi 时 Socket Timeout如果在刚刚连接 WiFi 的一瞬间连接 Socket，会出现 connect failed: ETIMEDOUT 的错误 为了避免这样的错误，得进行自动重连： 1234567891011while (true) &#123; try &#123; socket = Socket(serviceInfo.host, serviceInfo.port) Log.d(TAG, "Socket connected: $&#123;serviceInfo.host&#125;:$&#123;serviceInfo.port&#125;") break &#125; catch (err : ConnectException) &#123; Thread.sleep(1000) Log.e(TAG, err.toString()) Log.d(TAG, "Retrying") &#125;&#125; 5.2. RxJava 自动回收RxJava 中一些任务如果没有回收，会有一些潜在的问题。 例如，如果在某个 Activity 中使用了一个用于网络请求的 RxJava，此时如果 Activity 被系统关闭，会造成内存泄漏。 以下代码可以实现自动回收： 12345678910val compositeDisposable = new CompositeDisposable();val disposable = Observable.just(1) .subscribeOn(Schedulers.io()) .subscribe(number -&gt; Log.d(number));compositeDisposable.add(disposable);// 在 onDestroy 时调用compositeDisposable.dispose(); 更多详情，参照相关问题。 5.3. 服务始终保持运行本来可以直接用普通的 Service 来搞定，但是 Service 会不定时被系统回收，且国内安卓市场混乱，很容易被进制后台，所以这里采用前台服务 ForegroundService 来保持服务始终运行。 要注意的是，前台服务是在服务运行过程中启动的，而非启动服务的时候；另外前台服务运行中，通知栏会有无法关闭的通知来告知用户服务仍然在运行。 声明服务： 1&lt;service android:name=".PhoneStateReceiverService" android:exported="false" /&gt; 声明权限： 1&lt;uses-permission android:name="android.permission.FOREGROUND_SERVICE" /&gt; 注意这个权限必须运行时请求，同上述 android.permission.READ_PHONE_STATE 权限。 服务实现细节： 12345678910111213141516171819202122232425262728293031323334353637383940414243private val TAG = "TVPause." + PhoneStateReceiverService::class.java.simpleNameclass PhoneStateReceiverService : Service() &#123; companion object &#123; private const val CHANNEL_ID = "cn.andiedie.TVPause.PhoneStateReceiverService.CHANNEL" private const val NOTIFICATION_ID = 19210 &#125; override fun onCreate() &#123; super.onCreate() // Android O 开始需要管理通知的频道 if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.O) &#123; val name = getText(R.string.channel_name) val description = getText(R.string.channel_description).toString() val importance = NotificationManager.IMPORTANCE_DEFAULT val mChannel = NotificationChannel(CHANNEL_ID, name, importance) mChannel.description = description val notificationManager = getSystemService(Context.NOTIFICATION_SERVICE) as NotificationManager notificationManager.createNotificationChannel(mChannel) &#125; Log.d(TAG, "PhoneStateReceiverService create") &#125; private fun register() &#123; val builder = if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.O) &#123; Notification.Builder(this, CHANNEL_ID) &#125; else &#123; Notification.Builder(this) &#125; val notification = builder.setContentTitle(getText(R.string.notification_title)) .setContentText(getText(R.string.notification_message)) .setSmallIcon(R.mipmap.ic_launcher) .build() startForeground(NOTIFICATION_ID, notification) // 从这开始 服务就保持一直运行 // 将需要长时间运行的服务，例如电话状态接收函数放在这里注册 &#125; private fun unregister() &#123; unregisterReceiver(phoneStateReceiver) &#125; override fun onBind(intent: Intent?): IBinder? &#123; return null &#125;&#125; 5.4. Android P 明文传输错误Android 9.0 (API level 28) 开始默认禁止明文传输，因此 HTTP 会出错。 需要手动开启： 12345678910&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;manifest ...&gt; &lt;uses-permission android:name="android.permission.INTERNET" /&gt; &lt;application ... android:networkSecurityConfig="@xml/network_security_config" ...&gt; ... &lt;/application&gt;&lt;/manifest&gt; 更多详情，参照相关问题。 5.5. 关于屏幕旋转Android 在屏幕旋转的过程中，默认会销毁当前 Activity，然后重新渲染一个新的 Activity。可以通过配置修改这个表现。 保持竖屏： 123456789&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;manifest ...&gt; &lt;application ...&gt; &lt;activity android:screenOrientation="portrait" &gt; &lt;/activity&gt; &lt;/application&gt;&lt;/manifest&gt; 更多详情，参考这个链接。 6. 效果 请无视电视剧内容和手机来电头像🤠。 7. 下一步下一步可以考虑在电视装一个服务端，这样就可以非常详细地获得当前电视的运行情况，各种连接、操作也可以自定义搞定。]]></content>
      <categories>
        <category>Development</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Android 反编译、修改、重打包与签名]]></title>
    <url>%2Fposts%2F552a%2F</url>
    <content type="text"><![CDATA[这篇博客主要介绍如何使用 Apktool、dex2jar、jd-gui等工具反编译 Android APP、修改源码、重新打包并签名。 1. 工具安装1.1. ApktoolApktool 主要用于反编译和重编译 APK 文件。 Windows 和 Linux 安装方法参照：官方指南 macOS 安装方法如下： 右键保存启动脚本，命名为 apktool 下载最新版本的 Apktool，命名为 apktool.jar 将 apktool 和 apktool.jar 移动到 /usr/local/bin 目录下 使用 chmod +x apktool 和 chmod +x apktool.jar 添加运行权限 在命令行直接运行命令 apktool 即可，安装完成 1.2. dex2jardex2jar 主要用于将 dex 文件转为 jar 文件 从 GitHub 下载最新版本，并解压。运行解压后目录下的 d2j-dex2jar.sh 或 d2j-dex2jar.bat 即可。 1.3. jd-guijd-gui 主要用来可视化 jar 文件。 从 GitHub 下载最新版本，并解压。运行解压后目录下的 JD-GUI 即可。 macOS 下注意： 如果 jd-gui 无法打开，编辑 JD-GUI.app/Contents/MacOS/universalJavaApplicationStub.sh 123456789101112exec "$JAVACMD" \ -cp "$&#123;JVMClassPath&#125;" \ -Xdock:icon="$&#123;ResourcesFolder&#125;/$&#123;CFBundleIconFile&#125;" \ -Xdock:name="$&#123;CFBundleName&#125;" \ ## ----- 添加这两行 ----- --add-opens java.base/jdk.internal.loader=ALL-UNNAMED \ --add-opens jdk.zipfs/jdk.nio.zipfs=ALL-UNNAMED \ ## -------------------- $&#123;JVMOptions:+$JVMOptions &#125;\ $&#123;JVMDefaultOptions:+$JVMDefaultOptions &#125;\ $&#123;JVMMainClass&#125;\ $&#123;JVMArguments:+ $JVMArguments&#125; 详见 issue 2. 查看源码以小米投屏神器 APP 为例。 运行 d2j-dex2jar.sh 将 APK 中的 dex 文件转为 jar 文件： 12$ ./d2j-dex2jar.sh mi.apkdex2jar mi.apk -&gt; ./mi-dex2jar.jar 打开 jd-gui，将 mi-dex2jar.jar 拖进去，即可看到反编译后的源码。 3. 修改源码这里以增加 Log 为修改源码的例子。 jd-gui 只能查看源码，但是无法修改。要修改源码，只能修改 smali 文件，它类似于汇编，但是要简单很多。 首先得使用 apktool 进行反编译： 1apktool d mi.apk -o mi 这里将 mi.apk 进行反编译并将结果放到 mi 目录中。 首先找到需要添加 Log 的位置，建议在 jd-gui 中寻找，然后在 mi 目录中定位。 例如以下 class 和 smali 的对应关系 mi-dex2jar.jar!/com/xiaomi/mitv/phone/tvassistant/b/a.class mi/smali/com/xiaomi/mitv/phone/tvassistant/b/a.smali 打开 a.class 和 a.smali，首先看 java： 123456789public void a(int paramInt)&#123; String str1 = String.valueOf(System.currentTimeMillis()); String str2 = a(String.valueOf(paramInt), this.b, str1); new c(this.d, String.format("http://%s:6095/general?action=setVolum&amp;volum=%d&amp;ts=%s&amp;sign=%s", new Object[] &#123; this.a, Integer.valueOf(paramInt), str1, str2 &#125;), new c.a() &#123; public void a(int paramAnonymousInt, String paramAnonymousString) &#123;&#125; &#125;).d();&#125; 对应的 smali 文件内容，为了简单，我只提取了部分内容。 12345678910111213141516171819202122232425262728293031323334353637.method public a(I)V # a 是方法，p0 = this # a 接收一个参数, p1 = paramInt' # 定义了 8 个寄存器 .locals 8 .prologue .line 55 # 获取系统当前时间 invoke-static &#123;&#125;, Ljava/lang/System;-&gt;currentTimeMillis()J # 结果赋值给 v0 move-result-wide v0 # 调用 String.valueOf 方法，将 v0 转为字符串 invoke-static &#123;v0, v1&#125;, Ljava/lang/String;-&gt;valueOf(J)Ljava/lang/String; # 结果赋值给 v0 move-result-object v0 # 到这一步 # String str1 = String.valueOf(System.currentTimeMillis()); # 执行完了 .line 57 # 调用 String.valueOf 方法 p1 转为字符串 invoke-static &#123;p1&#125;, Ljava/lang/String;-&gt;valueOf(I)Ljava/lang/String; # 结果赋值给 v1 move-result-object v1 # 获取 this.b，也就是从 p1 中获取 b，并赋值给 v2 iget-object v2, p0, Lcom/xiaomi/mitv/phone/tvassistant/b/a;-&gt;b:Ljava/lang/String; # 将 v1，v2，v0 作为参数调用方法 a，并传递 p0 作为 this invoke-direct &#123;p0, v1, v2, v0&#125;, Lcom/xiaomi/mitv/phone/tvassistant/b/a;-&gt;a(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; # 将结果赋值给 v1 move-result-object v1 # 到这一步 # String str2 = a(String.valueOf(paramInt), this.b, str1); # 执行完了 ... 假设我们想要得知其中 this.b 的值，可以这样添加 Log： 12345678910111213141516171819202122232425262728293031323334353637383940414243.method public a(I)V # 额外定义 4 个寄存器用于存储 TAG .locals 12 .prologue .line 55 # 设置初始化TAG const-string v8, "AndiedieHack.currentTimeMillis" const-string v9, "AndiedieHack.param" const-string v10, "AndiedieHack.b" const-string v11, "AndiedieHack.result" invoke-static &#123;&#125;, Ljava/lang/System;-&gt;currentTimeMillis()J move-result-wide v0 invoke-static &#123;v0, v1&#125;, Ljava/lang/String;-&gt;valueOf(J)Ljava/lang/String; move-result-object v0 # 第一个 Log，使用 v8 作为 TAG，输出 v0 的值，即系统当前时间 invoke-static &#123;v8, v0&#125;, Landroid/util/Log;-&gt;d(Ljava/lang/String;Ljava/lang/String;)I .line 57 invoke-static &#123;p1&#125;, Ljava/lang/String;-&gt;valueOf(I)Ljava/lang/String; move-result-object v1 # 第二个 Log，使用 v9 作为 TAG，输出 v1 的值 # v1 是 p1 的字符串形式，p1 是函数参数 invoke-static &#123;v9, v1&#125;, Landroid/util/Log;-&gt;d(Ljava/lang/String;Ljava/lang/String;)I iget-object v2, p0, Lcom/xiaomi/mitv/phone/tvassistant/b/a;-&gt;b:Ljava/lang/String; # 第三个 Log，使用 v10 作为 TAG，输出 v2 的值，即 this.b invoke-static &#123;v10, v2&#125;, Landroid/util/Log;-&gt;d(Ljava/lang/String;Ljava/lang/String;)I invoke-direct &#123;p0, v1, v2, v0&#125;, Lcom/xiaomi/mitv/phone/tvassistant/b/a;-&gt;a(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; move-result-object v1 # 第四个 Log，使用 v11 作为 TAG，输出 v1 的值，即 str2 invoke-static &#123;v11, v1&#125;, Landroid/util/Log;-&gt;d(Ljava/lang/String;Ljava/lang/String;)I 到这一步，源码修改完成。接下来进行重新打包。 3. 重新打包与签名将修改后的内容重新打包为 APK： 1apktool b mi -o unsigned.apk 打包之后的 unsigned.apk 是没有签名的，无法安装。 签名需要使用一个 keystore，可以直接使用 Android Studio 为我们生成的 debug 用 keystore。 位置在 用户目录/.android/debug.keystore，alias 是 androiddebugkey，密码是 android 签名命令： 1jarsigner -keystore debug.keystore -signedjar signed.apk unsigned.apk androiddebugkey 输入密码即可。 4. 测试在手机上安装 signed.apk，注意如果之前已经安装了投屏神器，需要先卸载，因为两者的签名不一致。 运行 APP，调整音量，可以看到以下 Log：]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[移动设备抓包]]></title>
    <url>%2Fposts%2Fcc60%2F</url>
    <content type="text"><![CDATA[本文主要以 iOS 为例，演示如何使用 Charles 和 Wireshark 在移动设备上抓取 HTTPS、HTTPS、TCP 等协议的数据包。 以下称 PC 为抓包所用的计算机，手机为被抓包的移动设备。 1. 使用 Charles 抓取 HTTP首先安装 Charles，下载地址：官网。 使用 Charles 抓包要求 PC 和 手机必须位于同一个局域网下。 1.1. 配置 Charles打开 Charles，菜单 Proxy &gt; Proxy Settings... 进入代理设置，打开代理服务器。可以指定代理服务器运行的端口，这里使用默认端口 8888。 接下来获取 Charles 代理服务器局域网 IP，也就是本机在局域网的 IP。macOS 可以打开 System Preferences &gt; Network 中查看，当然也可以运行 ifconfig 查看。 至此，我们知道了 Charles 的代理服务器的地址是 192.168.31.110:8888。 1.2. 配置手机手机连接 PC 所在局域网的 WiFi，并配置代理服务器。iOS 示例如下： 1.3. 开始抓包此时直接从手机发起任何 HTTP 请求即可，PC 上的 Charles 会显示所有 HTTP 数据包。若想要停止抓包，请关闭 Charles 并在手机上取消使用代理服务器。 2. 使用 Charles 抓取 HTTPS为了使 Charles 能够成为中间人抓取 HTTPS，必须首先安装并信任 Charles 签发的 CA 证书。 2.1. 设置代理服务器首先按照上一步提到的步骤，打开 Charles 的代理服务器，并配置手机连接该代理服务器。只有这样，才能下载 Charles 签发的证书。 2.2. 安装证书在手机上访问网页 chls.pro/ssl，iOS 上注意使用 Safari 打开该页面才能正常显示证书。 注意，安装时需要输入手机密码。 2.3. 信任证书iOS 进入设置 &gt; 通用 &gt; 关于本机 &gt; 证书信任设置，并设置对 Charles 证书的信任。 2.4. 配置 Charles默认 Charles 不会代理任何 HTTPS 请求，需要在 Proxy &gt; SSL Proxying Setting... 中打开 HTTPS 代理： 注意，Charles 代理 HTTPS 采用白名单机制，只有名单中的地址才会被代理 HTTPS 协议。如果想代理全部地址的 HTTPS，在添加地址时只需要在 Host 输入 * 即可。 2.5. 开始抓包此时直接从手机发起任何 HTTPS 请求即可，PC 上的 Charles 会显示所有 HTTPS 数据包。若想要停止抓包，请关闭 Charles 并在手机上取消使用代理服务器。 3. 使用 Wireshark 抓取首先安装 Wireshark，下载地址：官网。 Wireshark 可以监听任何网卡中的所有网络流量，因此既然我们要监听手机上的网络流量，就需要建立一个映射到手机上的虚拟网卡。 3.1. 安装 Xcode由于建立虚拟网卡需要使用命令 rvictl，这是 Xcode 工具链之一，所以需要安装 Xcode。可以从从 App Store 或 这里 下载并安装 Xcode。 下载并安装之后，请至少运行一次 Xcode ，Xcode 会自动安装必要的工具。 3.2. 获取设备 UDID首先，需要获取设备的 UDID。将手机通过数据线连接电脑，打开 iTunes，单击 iPhone 的序列号： 设备的 UDID 就会出现，右键可以复制： 3.3. 配置虚拟网卡在终端运行命令： 123$ rvictl -s [YOUR UDID]Starting device [YOUR UDID] [SUCCEEDED] with interface rvi0 可以看到，虚拟网卡 rvi0 已经建立。 3.4. 开始抓包打开 Wireshark，选择虚拟网卡 rvi0 即可开始抓包。 在手机上发送任意数据包即可。 3.5. 停止抓包停止抓包后，除了关闭 Wireshark，还需要移除虚拟网卡。 在终端运行命令： 123$ rvictl -x [YOUR UDID]Stopping device [YOUR UDID] [SUCCEEDED]]]></content>
  </entry>
  <entry>
    <title><![CDATA[Bilibili Watchlater Plus : 让 B 站的稍后再看更好用]]></title>
    <url>%2Fposts%2F7a6d%2F</url>
    <content type="text"><![CDATA[B 站的稍后再看功能明显是一个半成品，有许多不完善的地方，其中最致命的就是无法加入和播放番剧。最近我终于忍受不了它的诸多问题，着手开发了一个油猴脚本 Bilibili Watchlater Plus，对稍后再看功能进行了一番改造。开源地址：bilibili-watchlater-plus。 1. 问题B 站的稍后再看功能主要有三点让我觉得不能忍受： 无法将番剧加入稍后再看。 即使通过一些特别的方式将番剧加入了稍后再看，也无法播放。 稍后再看按钮没有初始状态。 一句话总结理想状态就是，已加入的视频初始显示勾选，没加入的视频初始不勾选；点击未勾选的按钮，将视频加入稍后再看；点击已勾选的按钮，将视频移出稍后再看。 然后 B 站目前无论一个视频有没有被加入稍后再看，它的按钮都是同一个初始状态，也就是说下面的第一张图。 没加入稍后再看的视频的默认初始状态： 已被加入稍后再看的视频的理想初始状态： 2. 初级阶段在开发这个正式版本之前，我曾写过一个临时用用的版本，主要作用于首页右上角的动态悬浮窗，因为那是我用的最多的地方。 这个版本可以从这里获取：Bilibili Watchlater Plus 0.0.1。 当时解决了在动态悬浮窗上已经可以将番剧加入稍后再看，稍后再看按钮有初始状态。对于在稍后再看中的番剧视频，则是采用直接跳转到播放链接的方式解决。 上述的临时版本让我在一段时间内有了比较舒适的使用体验，但是近段时间 B 站更改了一些 UI 和 API 接口，原来的脚本失效了。正巧假期时间比较充裕，我就借此机会开发了一个比较完整的版本。 3. 实现3.1. 如何实现首先考虑各种需求该如何实现。 让番剧也可以加入稍后再看。 首先是可行性。B 站的稍后再看 API 需要 aid （即视频 ID）作为参数，而番剧的单集 ID 是 epid。只需要通过番剧播放页就可以获取 epid 对应的 aid，再调用 API 就可以将番剧加入稍后再看。 然后是如何实现。目前常规视频在封面图右下角都会有一个稍后再看按钮，点击就可以添加或删除稍后再看，然后番剧的封面却没有。因此实现番剧加入稍后再看非常简单，只需要给番剧的封面也添加一个稍后再看按钮就可以了。 稍后再看按钮的初始状态。 在之前提到的初级版本里，我解决这个问题的方法非常粗暴：首先通过 API 确定每个视频是否已经加入了稍后再看，对于已经加入稍后再看的视频，给它的按钮添加一个 class 改变样式。 这样的好处是非常简单粗暴，几行就可以写完所有逻辑。但是坏处也显而易见，按钮仅仅是样式改变了，功能却没有，导致点击一个已勾选的按钮结果却又是将视频加入稍后再看，而不是勾选按钮应该做的”将视频移出稍后再看“。简单的来说就是按钮功能和样式的不统一。 要实现按钮功能和样式的统一，只能抛弃原有的按钮，自己从头开始为每个视频添加稍后再看按钮。这样按钮的样式、功能都可以自己控制，唯一的缺点就是需要一定的工作量。 可以在稍后再看播放番剧。 这个是最让我头疼的地方就是如何在稍后再看中播放番剧。最后我发现 Hack B 站的视频播放器使之能播放番剧太麻烦了，不如我自己实现一个稍后再看的播放逻辑。 原本的播放逻辑是 B 站在一个专为稍后再看编写的单页面应用中，逐个播放视频，当遇到番剧时就无法解析并弹窗。为了简化开发，我设定的新逻辑是，点击稍后再看的视频直接跳转到常规视频播放页面，并在页面左边添加一个汉堡菜单，可以看到并跳转到其他稍后再看。 3.2. 监听页面变化上面提到，我们需要替换、添加按钮，但这会遇到几个问题： 由于油猴脚本可能在任何时候插入页面，此时页面的状态不确定 页面可能在任何时候更新，比如加载中的页面或者用户点击导致页面变化 最理想的实现是，监听页面的变化。这里提出一个需求，我需要寻找页面中所有的旧按钮，替换成新的自定义的按钮。利用 HTML 提供的 MutationObserver API，我们可以订阅某个根节点下的所有变化，我们只需要在变化的节点下寻找有没有旧按钮就行了。 但是现在出现了另一个需求：添加按钮。 添加按钮的逻辑是，找到一个父元素，这个父元素原本应该有稍后再看按钮，而现在却没有，那么我们就向父元素里添加自定义的按钮。也就是说我们搜索的检查点有两个，父元素和是否有子元素，只有”找到父元素“和”按钮子元素不存在“同时满足时，才添加自定义按钮。 让我们回想刚刚提到的方法，首先 MutationObserver 会提供一个有更改的节点，如果目标父元素和子元素都位于这个节点下，那么没有问题，我们可以很轻松的搜索到。但如果 MutationObserver 回调的节点位于父元素和子元素之间，搜索就会变得略微复杂，因为我们需要通知向两个方向搜索。 最终妥协了上述两种情况，使用的解决方案是，使用 MutationObserver 监听这个 document.body 的变化。在每次变化发生之后，遍历整个文档寻找目标节点。 这样的做法好处是，遍历的逻辑非常简单，直接使用 JQuery 就可以做到。坏处是更加耗时，因为每次整个文档的任意一处发生变化时，哪怕变化的地方与我们的目标毫无关系，都需要遍历整个文档树，而且通常整个 HTML 文档会在短时间内频繁地更新。为了解决性能问题，使用 Lodash 的 debounce 函数对回调去抖动，这样短时间内的频繁更新只会触发一次搜索。 大致代码如下： 12345678910111213141516new MutationObserver((mutationList) = &#123; for (const mutation of mutationList)&#123; // 只关心添加节点的变化 if (mutation.addedNodes.length) &#123; // 200 毫秒内的频繁调用只会触发一次 _.debounce(() =&gt; &#123; $('...').each((index, ele) =&gt; &#123; // 找到的目标 &#125;); &#125;, 200); &#125; &#125;&#125;).observe(document.body, &#123; childList: true, subtree: true&#125;); 3.3. 异步更新状态在开发中还遇到一个小情景：现在所有的稍后再看按钮都成功替换成了自定义的按钮，然而因为稍后再看列表是异步获取的，没办法同步地给这些按钮设置是否勾选的状态。 那么如何异步地给按钮们更新状态呢？ 一个最简单粗暴的思路就是：按钮默认都是不勾选的状态。此时去获取稍后再看列表，待数据返回后，再从页面中找回所有的按钮，依次给他们分配状态。 12345678910111213for (const oldButton of oldButtons) &#123; const button = document.createElement('div'); button.aid = '...'; // 默认不勾选 button.checked = false; button.className = 'watch-later-plus-button'; oldButton.replaceWith(button);&#125;const watchlaterList = await getWatchlaterList();$('.watch-later-plus-button') .filter('...') // 根据 watchlaterList 过滤出需要勾选的按钮 .each((_, ele) =&gt; ele.checked = true); 上面的想法可以通过保存按钮引用的方式减少一次遍历： 12345678910111213const newButtons = [];for (const oldButton of oldButtons) &#123; const button = document.createElement('div'); button.aid = '...'; // 默认不勾选 button.checked = false; newButtons.push(buttons); oldButton.replaceWith(button);&#125;const watchlaterList = await getWatchlaterList();buttons.filter('...') // 根据 watchlaterList 过滤出需要勾选的按钮 .forEach((ele) =&gt; ele.checked = true); 上面两个方法本质是一样的，在创建按钮之后单独维护了一系列用于更新状态的语句。 我们可以利用闭包以及 Promise 的特性，写出这样的方法： 12345678910111213141516171819const watchLaterList = (() =&gt; &#123; let promise; return () =&gt; &#123; if (!promise) &#123; promise = getWatchLaterList(); &#125; return promise; &#125;;&#125;)();for (const oldButton of oldButtons) &#123; const button = document.createElement('div'); button.aid = '...'; watchLaterList().then(list =&gt; &#123; button.checked = list.includes(button.aid); &#125;); buttons.push(buttons); oldButton.replaceWith(button);&#125; 这样更新状态的逻辑就不需要单独维护了。 4. 现状和吐槽使用脚本之后，上面提到的 B站稍后再看的问题都得到了解决，特别是番剧也支持稍后再看之后，使用体验非常棒。 不要嫌弃我的 UI，又不是不能用。之后 B 站再改 UI 或 API 的时候再更新吧。 吐槽一下 B 站的前端，写个新版本的 UI 还只有播放界面才有，还是常规视频的播放界面有新 UI 而番剧的播放界面没有；其他地方都是普通的多页应用，但是到了稍后再看和个人空间确实单页面应用；就一个稍后再看的按钮的逻辑，在首页、动态悬浮窗、动态首页、空间页面的实现居然都是不一样的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[常用的 Badge]]></title>
    <url>%2Fposts%2F5d4d%2F</url>
    <content type="text"><![CDATA[在开源项目的 Readme 中添加 Badge 已经成为了一种浪漫。这里列举一些个人常用的 Badge，供日后参考。 主要使用的是 shields.io 提供的服务，通过它获得的 Badge 可以定制样式、颜色、图标等。 1. 仓库状态 Travis CI 1![](https://img.shields.io/travis/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) Coveralls 1![](https://img.shields.io/coveralls/$&#123;VSC_TYPE&#125;/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) Code Climate maintainability 1![](https://img.shields.io/codeclimate/maintainability/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) 2. GitHub GitHub issues 1![](https://img.shields.io/github/issues-raw/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) GitHub license 1![](https://img.shields.io/github/license/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) GitHub release 1![](https://img.shields.io/github/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) Contributions welcome 1![](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat-square) 3. Npm Npm package vulnerabilities 1![](https://img.shields.io/snyk/vulnerabilities/npm/$&#123;PACKAGE&#125;.svg?style=flat-square) Dependencies 12![](https://img.shields.io/david/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square)![](https://img.shields.io/david/dev/$&#123;USER&#125;/$&#123;REPO&#125;.svg?style=flat-square) Npm download 1![](https://img.shields.io/npm/dt/$&#123;PACKAGE&#125;.svg) Npm package version 1![](https://img.shields.io/npm/v/$&#123;PACKAGE&#125;.svg?style=flat-square)]]></content>
      <categories>
        <category>Development</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[115 账号共享之路]]></title>
    <url>%2Fposts%2Fdbf%2F</url>
    <content type="text"><![CDATA[115 的离线下载功能确实强悍，但是 500 元一年的会员价格也不便宜。于是我就与三个朋友一起合买了一年会员，准备四人共享使用。但是 115 的单点登录却给共享带来了很多限制，于是我们探索了诸多共享方案，期间历程就便成了这篇博文。 1. 115 的限制 单点登录 115 在所有客户端，包括网页端，PC 端（本质就是网页端）和手机端都实行单点登录。这就意味着，只要有任何一个客户端通过账号密码登录成功，之前的所有登录都会失效，无论是什么端。 115 浏览器 在网页端只能通过手机端扫码才能登陆，在 115 浏览器上可以通过账号密码登录，但是初次登录依然需要手机接收验证码。不过整体来说就 115 服务的使用上，115 浏览器还是要优于 Chrome：在 115 浏览器上下载 115 资源可以支持多线程下载和断点续传；且在 115 浏览器上打开磁力链接可以直接启动 115 离线下载。但是 115 浏览器 Chromium 版本还停留在 54，且标签页开的一多就卡顿，所以也只能当做 115 客户端用。 2. 瞎搞阶段一开始我们四人并没有想出如何破解 115 的单点登录限制。因此临时的共享方案是“二级离线下载”。具体如下： 我们在校内有一台公用电脑，24 小时开机并保持 115 登录状态。 任何人有下载需求时，就通过远程桌面连接公用电脑，将资源下载到公用电脑上。 公用电脑下载结束后，利用校园的百兆内网，通过 FTP 传回自己的电脑。 这当然有诸多限制： 在公网环境下，无论是远程桌面控制内网的公用电脑，还是 FTP 从内网公用电脑取下载资源都比较困难。 远程桌面是抢占式的，也就是说一个人在使用过程中会被另一个登录的人挤下去。 “二级离线下载”永远还是要多一步，非常麻烦。 为了解决上述问题，我们也付出了一些努力： 通过内网穿透，在公网也能轻松访问公用电脑。但是我的服务器水管太小，用 FTP 取回资源的速度太慢。 为了解决远程桌面抢占式的问题，我们在公用电脑上搭建了一个状态服务器，可以随时显示当前公用电脑有没有被使用。接着制作了一个远程桌面的脚本，先取公用电脑状态，只有空闲时才会继续启用远程桌面。 虽然通过上面两个 workaround 解决了部分问题，但是水管太小，操作麻烦的本质问题还是没有得到解决，再继续下去只是在点错的技能树继续错下去而已。 3. 利用 Cookies 共享账号其实很多人应该看到这里应该会嘲笑我，因为用 Cookies 来共享账号应该是非常容易想到的事情。 确实，当时我的第一个想法也是利用 Cookies，但是由于学艺不精，我测试时是通过 document.cookie 提取 Cookies。这当然会失败，当时愚蠢的我就这么放弃了 Cookies 的方法，而走了上面的歪路。 具体为何失败，以及转机是什么，之后再聊。 3.1. 基本原理115 的用来记录用户登录状态的 Cookies 是 Session 级别的。也就是说，一旦浏览器被关闭，这些 Cookies 就会被删除。 重点在于删除而不是失效，也就是说说被删除的 Cookies 是有效的。于是我们只需要在成功登陆之后，将 Cookies 保存下来，并在需要共享的浏览器上套用这些 Cookies 就好了。并且 Session 级别的 Cookies 是没有过期时间的，所以理论上只要服务器不做相关验证，我们可以永久维持登录状态。 3.2. 转机上面提到的转机就是这个 Chrome 插件：EditThisCookie。 这个插件主要就是为 Chrome Extension Cookies API 提供了 GUI 界面，从而使开发者可以很方便地通过 Chrome 扩展的能力编辑 Cookies。 稍加尝试就会发现，通过 EditThisCookie 提取的 Cookies，或者说通过 Chrome Extension Cookies API 提取的 Cookies 和 document.cookie 提取的 Cookies 完全不同。 我们以 115 为例： 通过 document.cookie 提取的 Cookies： 通过 EditThisCookie 提取的 Cookies： 这里实际上保存登录状态的三个 Cookies：UID、CID 和 SEID 在前者都找不到，反而一些无关紧要的 Cookies 都能获取到。这是因为在一些关键的 Cookies 上，通常会多设置一个 flag 叫 HttpOnly。 根据 MDN 的解释，为避免跨域脚本 (XSS) 攻击，通过 JavaScript 的 document.cookie 无法访问带有 HttpOnly 标记的 Cookies，它们只会在 HTTP 请求是被发送给服务端。 因此可以很清楚的看到，在 115.com 域下共有 7 个 Cookies，其中 4 个被设置了 HttpOnly，因此 document.cookie 只能获取到另外 3 个；而 Chrome Extension Cookie API 则可以获取所有 Cookies。 3.3. SyncMyCookie 诞生虽然使用 EditThisCookie 已经能够轻松的导入和导出 Cookies，实现分享账号。但是每次更新登录状态时都需将 JSON 格式的 Cookies 信息分享给别人，且对于 Session 级别的 Cookies，每次打开浏览器都必须重新导入一次，不够方便。 为了解决上面的问题，我编写了 Chrome 插件 SyncMyCookie。 它的工作原理也非常简单，使用 Chrome Extension Cookies API 从浏览器提取指定域名下的所有 Cookies，并将这些 Cookies 经过 AES-128-CBC 加密后保存在 GitHub Gist 中。这里 GitHub Gist 只是充当一个存储作用。 在此基础上，SyncMyCookie 提供了两个自动化功能： Auto Merge：可以在浏览器启动时自动将指定的 Cookies 合并进浏览器，特别适合 Session 级别的 Cookies。 Auto Push：在指定的 Cookies 发生变化时，自动推送保存。 4. 总结使用 SyncMyCookie 共享 115 账号基本做到了我能想象地最好体验： 我在自己的 115 浏览器安装插件并设置自动推送 115 的 Cookies 共享账号的朋友在 115 浏览器安装插件并设置自动合并 115 的 Cookies 每个人都可以满速下载，随意使用任何功能。 SyncMyCookie 也可以随意同步任何在浏览器提供服务，并使用 Cookies 记录登录状态的应用。简单测试了一下 Bilibili、爱奇艺、优酷、腾讯等视频网站都是可以使用的。]]></content>
      <categories>
        <category>Trivia</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mocha 复用测试用例]]></title>
    <url>%2Fposts%2Fcc67%2F</url>
    <content type="text"><![CDATA[在使用 Mocha 进行单元测试时，经常会有复用测试用例的需求。例如定义了一组测试用例后，希望在多种环境下都使用这组用例进行测试。 1. 测试环境首先简单地搭建一个测试环境。 创建项目： 1234mkdir mocha-reusecd mocha-reuseyarn init -yyarn add -D mocha 项目目录结构如下： index.js test index.test.js 其中 index.js 内容如下： 12345678910111213141516171819202122// index.jsmodule.exports = class Human &#123; constructor(name, age) &#123; if (typeof name === 'string') &#123; this.name = name; &#125; else if (name instanceof Buffer) &#123; this.name = name.toString(); &#125; else &#123; throw TypeError('Name can only be string or buffer'); &#125; if (typeof age === 'number') &#123; this.age = age; &#125; else if (typeof age === 'string') &#123; this.age = Number(age); &#125; else &#123; throw TypeError('Age can only be number or string'); &#125; &#125; toString() &#123; return `$&#123;this.name&#125;: $&#123;this.age&#125;`; &#125;&#125; 逻辑非常简单，Human 类构造时需要两个参数，name 支持 string 和 Buffer；age 支持 number 和 string。 测试内容是，构造一个 Human 实例后测试 name、age 和 toString() 是否正确。 2. 无复用版本为了提高测试覆盖率，必须使用每一种可能的参数组合实例化 Human。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// test/index.test.jsconst assert = require('assert');const Human = require('../index');describe('Test with string name and number age', () =&gt; &#123; let human; before(() =&gt; &#123; human = new Human('A', 1); &#125;); it('Check name', () =&gt; &#123; assert(human.name === 'A'); &#125;); it('Check age', () =&gt; &#123; assert(human.age === 1); &#125;); it('Check toString', () =&gt; &#123; assert(human.toString() === 'A: 1'); &#125;);&#125;);describe('Test with buffer name and number age', () =&gt; &#123; let human; before(() =&gt; &#123; human = new Human(Buffer.from('A'), 1); &#125;); it('Check name', () =&gt; &#123; assert(human.name === 'A'); &#125;); it('Check age', () =&gt; &#123; assert(human.age === 1); &#125;); it('Check toString', () =&gt; &#123; assert(human.toString() === 'A: 1'); &#125;);&#125;);describe('Test with string name and string age', () =&gt; &#123; let human; before(() =&gt; &#123; human = new Human('A', '1'); &#125;); it('Check name', () =&gt; &#123; assert(human.name === 'A'); &#125;); it('Check age', () =&gt; &#123; assert(human.age === 1); &#125;); it('Check toString', () =&gt; &#123; assert(human.toString() === 'A: 1'); &#125;);&#125;);describe('Test with buffer name and string age', () =&gt; &#123; let human; before(() =&gt; &#123; human = new Human(Buffer.from('A'), '1'); &#125;); it('Check name', () =&gt; &#123; assert(human.name === 'A'); &#125;); it('Check age', () =&gt; &#123; assert(human.age === 1); &#125;); it('Check toString', () =&gt; &#123; assert(human.toString() === 'A: 1'); &#125;);&#125;); 可以看到，除了初始化不同之外，所有的测试样例都是一样的，因此我们必须想办法复用测试用例 3. 复用测试用例 在 test 目录下创建新的文件 share.js，将复用的用例放在里面： 12345678910111213const assert = require('assert');module.exports = function () &#123; it('Check name', function () &#123; assert(this.human.name === 'A'); &#125;); it('Check age', function () &#123; assert(this.human.age === 1); &#125;); it('Check toString', function () &#123; assert(this.human.toString() === 'A: 1'); &#125;);&#125;; 此时目录结构变为： index.js test index.test.js share.js index.test.js 变为： 123456789101112131415161718192021222324252627282930const Human = require('../index');const check = require('./share');describe('Test with string name and number age', () =&gt; &#123; before(function () &#123; this.human = new Human('A', 1); &#125;); check();&#125;);describe('Test with buffer name and number age', () =&gt; &#123; before(function () &#123; this.human = new Human(Buffer.from('A'), 1); &#125;); check();&#125;);describe('Test with string name and string age', () =&gt; &#123; before(function () &#123; this.human = new Human('A', '1'); &#125;); check();&#125;);describe('Test with buffer name and string age', () =&gt; &#123; before(function () &#123; this.human = new Human(Buffer.from('A'), '1'); &#125;); check();&#125;); 要注意的是，这里在所有涉及 this 的函数上，不要使用箭头函数。 4. 参考Shared Behaviours]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TypeScript 初入坑]]></title>
    <url>%2Fposts%2F7625%2F</url>
    <content type="text"><![CDATA[本文主要介绍我入坑 TypeScript 以后总结的一些相关配置，包括： TypeScript 安装、配置与调试 TSLint 配置 TypeScript 编写与发布 npm 包 TypeScript 与 webpack、babel TypeScript 测试与覆盖率 1. TypeScript 基本配置1.1. 安装 TypeScript全局安装： 1yarn global add typescript 不过我个人还是更加推荐在每个 TypeScript 项目下都安装一个开发依赖： 1yarn add -D typescript 如果是在 Node.js 环境下编写，还推荐安装相应的类型声明： 1yarn add -D @types/node 安装完后可以使用 tsc 对 TypeScript 文件进行编译： 1234# 全局安装tsc test.ts# 项目安装npx tsc test.ts 使用 tsc --help 可以查看到编译选项。 1.2. 配置 tsconfig.jsontsc 提供的编译选项十分丰富，我们也经常需要在项目编译时指定一些参数，然后每次编译时都手动输入这些参数非常麻烦，我们可以在项目根目录创建 tsconfig.json 文件作为配置文件，运行 tsc 且不指定输入文件时，会默认应用文件中的配置。 一个简单的 tsconfig.json 如下： 123456789101112&#123; "compilerOptions": &#123; "outDir": "./dist", "noImplicitAny": true, "module": "CommonJS", "declaration": true, "target": "ES2015", "strict": true &#125;, "include": ["src"], "exclude": ["node_modules"]&#125; outDir 指定了目标文件输出位置 noImplicitAny 检查在源代码中不能有隐式声明的 Any 类型 module 指定了模块规范 declaration 输出目标文件时同时输出类型声明文件 target 指定 JavaScript 的版本 strict 严格模式 include 和 exclude 指定输入和排除目录 详细配置可见 tsconfig.json 。 配置完后直接运行 tsc 即可。 1.3. 调试 TypeScript这里演示如何在 VS Code 中调试 TypeScript。 调试的配置文件位于 .vscode/launch.json，建议将整个 .vscode 文件夹加入 .gitignore中。 调试编译后的 JavaScript一种最简单的方法是调试编译后的 JavaScript： 在 .vscode/launch.json 中加入配置： 1234567891011121314&#123; "version": "0.2.0", "configurations": [ &#123; "type": "node", "request": "launch", "name": "Debug JavaScript", "program": "$&#123;workspaceRoot&#125;/dist/index.js", "args": [], "protocol": "inspector", "cwd": "$&#123;workspaceRoot&#125;" &#125; ]&#125; 直接调试 TypeScript直接调试 JavaScript 的好处是配置简单、但每次都需要显式地编译非常麻烦。这里使用 ts-node 作为运行环境，就可以直接调试 TypeScript 了。 安装 ts-node： 1yarn add -D ts-node 在 tsconfig.json 中开启 sourceMap： 12345678910111213&#123; "compilerOptions": &#123; "outDir": "./dist", "noImplicitAny": true, "module": "CommonJS", "declaration": true, "target": "ES2015", "strict": true, "sourceMap": true &#125;, "include": ["src"], "exclude": ["node_modules"]&#125; 配置 .vscode/launch.json： 123456789101112131415&#123; "version": "0.2.0", "configurations": [ &#123; "type": "node", "request": "launch", "name": "Debug TypeScript", "args": ["$&#123;relativeFile&#125;"], "runtimeArgs": ["--nolazy", "-r", "ts-node/register"], "sourceMaps": true, "protocol": "inspector", "cwd": "$&#123;workspaceRoot&#125;" &#125; ]&#125; 2. TSLint2.1. 基本配置编写 JavaScript 时一般会使用 ESLint 对代码进行检查。同样的， 在 TypeScript 中我们使用 TSLint。 首先需要安装依赖： 1yarn add -D tslint 接着进行配置，在根目录创建 tslint.json 文件，一个典型的例子： 123456789&#123; "extends": ["tslint:recommended"], "rules": &#123; "quotemark": [true, "single"], "no-empty": [true, "allow-empty-functions"], "trailing-comma": [true, &#123;"multiline": "always", "singleline": "never"&#125;], "interface-name": false &#125;&#125; extends 预设的规则模板 rules 自定义规则 以上是我通常使用的规则，它在推荐规则的基础上，将字符串改为单引号、允许空函数、要求行尾逗号以及不要求接口名称必须以 I 开头。 完成安装和配置就可以对代码进行检查了： 1npx tslint -p tsconfig.json 2.2. VS Code 配置让 VS Code 支持 TSLint 错误显示和自动修复，需要在 VS Code 中安装 TSLint 插件。 在设置中将 TSLint 插件的 Auto Fix On Save 功能打开即可。 3. TypeScript 发布 npm 包为了兼容 JavaScript 社区，发布到 npm 的包必须是 JavaScript 而不是 TypeScript。 所以发布一个包的步骤变为： 编译 TypeScript 让 npm 只识别编译后的 JavaScript 发布 3.1. 编译在 npm scripts 中添加 build： 123"scripts": &#123; "build": "tsc"&#125; 3.2. 修改 npm files在 package.json 中新加一个字段 files 指定 npm 识别的文件： 123"files": [ "dist/**/*"] 这样当 npm 发布包的时候，就只会放 files 字段中指定的文件打包发布。当然，npm 会自动识别 LICENSE、README.md 和 package.json。 按照如上配置，最后发布的包的目录结构为： dist index.js ... LICENSE package.json README.md 3.3. 自动化谁都不想每次 npm publish 前都手动运行一次 yarn build ，因此你可以再添加一个 npm scripts： 1234"scripts": &#123; "build": "tsc", "prepublishOnly": "yarn bulid"&#125; 这样每次 npm publish 前就会自动进行编译。 3.4. 避免丢失类型声明为了兼容 JavaScript 社区，我们往 npm 发布了编译后的 JavaScript 代码，但编译成 JavaScript 后会失去类型声明。 我们可以在 tsconfig.json 中将 declaration 设为 true，使得编译时输出类型声明文件。 这样发布的 npm 包目录如下： dist index.js index.d.ts … LICENSE package.json README.md 这样，JavaScript 和 TypeScript 都可以正常引用编译后的代码，且 TypeScript 还会自动引用同目录下的类型声明文件。（在 VS Code 下，JavaScript 也会自动引用类型声明文件作为代码提示。） 4. TypeScript 与 webpack4.1. webpack 篇如果使用 TypeScript 编写浏览器上运行的代码，一般需要配合 webpack 工作。 首先安装依赖： 1yarn add -D webpack webpack-cli awesome-typescript-loader 在项目根目录下创建 webpack 配置文件 webpack.config.js： 1234567891011121314151617181920212223242526272829const path = require('path');function generateConfig(name) &#123; const mode = name.includes('min') ? 'production' : 'development'; return &#123; entry: './src/index.ts', mode, module: &#123; rules: [ &#123; test: /\.ts?$/, loader: 'awesome-typescript-loader', &#125;, ], &#125;, resolve: &#123; extensions: [ '.ts', '.js' ], &#125;, output: &#123; filename: `$&#123;name&#125;.js`, path: path.resolve(__dirname, 'dist'), library: 'Test', libraryTarget: 'umd', &#125;, devtool: 'source-map', &#125;;&#125;module.exports = [generateConfig('test'), generateConfig('test.min')]; 这里的配置文件一次性生成了两个配置： 在开发环境下编译 index.ts 为 test.js，并生成 source map：在这种情况下，输出代码不会被压缩。 在生产环境下编译 index.ts 为 test.min.js，并生成 source map：在这种情况下，输出代码会被压缩。 注意：上述配置第 22 和 23 行定义了输出为 library，即只要运行编译后的代码，入口就会被自动挂载到浏览器的全局下。 例如 JQuery 可以这么配置： 12345678...output: &#123; filename: 'jquery.min.js', path: path.resolve(__dirname, 'dist'), library: '$', libraryTarget: 'umd'&#125;,... 配置完成后，运行下面的命令进行编译： 1npx webpack 4.2. Babel 篇为了将新版本的 JavaScript 特性翻译成兼容性更高的 JavaScript，我们需要引入 Babel。 首先安装依赖： 1yarn add -D @babel/core @babel/plugin-transform-runtime @babel/preset-env @babel/preset-typescript @babel/runtime babel-loader 修改 webpack.config.js： 1234567891011121314151617181920212223242526272829const path = require('path');function generateConfig(name) &#123; const mode = name.includes('min') ? 'production' : 'development'; return &#123; entry: './src/index.ts', mode, module: &#123; rules: [ &#123; test: /\.ts?$/, loader: ['babel-loader', 'awesome-typescript-loader'], &#125;, ], &#125;, resolve: &#123; extensions: [ '.ts', '.js' ], &#125;, output: &#123; filename: `$&#123;name&#125;.js`, path: path.resolve(__dirname, 'dist'), library: 'Test', libraryTarget: 'umd', &#125;, devtool: 'source-map', &#125;;&#125;module.exports = [generateConfig('test'), generateConfig('test.min')]; 唯一的变化是 12 行，loader 中加入了 babel-loader。 接下来在项目根目录新建 Babel 配置文件 .babelrc，典型配置如下： 123456789101112&#123; "plugins": ["@babel/plugin-transform-runtime"], "presets": [ "@babel/typescript", ["@babel/env", &#123; "modules": "umd", "targets": &#123; "browsers": [ "&gt;1%" ] &#125; &#125;] ]&#125; 编译后的版本将支持使用率大于 1% 的浏览器。 5. TypeScript 测试5.1. 使用 Mocha 测试这里使用的测试框架是 Mocha，断言库是简单优秀的的 power-assert。 安装依赖： 1yarn add -D mocha @types/mocha power-assert espower-typescript 假定现在目录结构如下： index.ts test index.test.ts 其中 index.ts ： 123export function add(a: number, b: number): number &#123; return a + b;&#125; index.test.ts： 12345678import assert = require('assert');import &#123; add &#125; from '../index';describe('Test add function', () =&gt; &#123; it('Add', () =&gt; &#123; assert(add(1, 2) === 3); &#125;);&#125;); 在 npm scripts 中添加： 123"scripts": &#123; "test": "mocha --require espower-typescript/guess test/**/*.ts"&#125; 运行测试： 1yarn test 5.2. 使用 istanbul 生成覆盖率报告首先安装依赖： 1yarn add -D istanbul@1.1.0-alpha.1 ts-node 注意这里必须安装 1.1.0-alpha.1 版本的 istanbul。 在 npm scripts 中添加： 123"scripts": &#123; "coverage": "istanbul cover -e .ts _mocha -- --require ts-node/register test/**/*.ts"&#125; 这里用来生成覆盖率的命令有些复杂，解析如下： 1234567istanbul \ # istanbul 命令cover \ # istanbul 子命令-e .ts \ # istanbul 参数，指定 .ts 文件_mocha \ # 在同一个进程内运行 mocha 保证 istanbul 能获得输出-- \ # 两短横线后的参数会传递给 mocha 而非 istanbul--require ts-node/register \ # 使用 ts-node 编译test/**/*.ts # 测试文件 运行 yarn coverage 就会跑完测试代码并在 coverage 目录下生成覆盖率报告。建议将 coverage 添加到 .gitignore。]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于 Android Accessibility 实现一键拨打微信电话]]></title>
    <url>%2Fposts%2Fdf57%2F</url>
    <content type="text"><![CDATA[本文对小项目 QuickWeChatCall 进行了简要的回顾。 1. 概述1.1. 动机奶奶非常喜欢和我跟姐姐视频聊天，但是微信的视频步骤实在太过复杂，对于打电话都有困难的奶奶来说几乎不可能独立使用的。为此我编写了 QuickWeChatCall 这个工具，用于帮助需要的人一键发起微信视频。 ビデオチャットしましょう、おばあちゃん。:-) 项目地址：QuickWeChatCall 下载：Release 使用教程：Usage 1.2. 结果运行截图： 实现了以下功能： 一键发起视频聊天 自动接听视频 / 语音聊天 快捷联系人列表 1.3. 启发在自己开发之前，先测试了两个网络上提供的解决方案： Auto.js，支持使用 JavaScript 操控 Android 的无障碍服务。优点是开发迅速，只需要几行 JavaScript 代码就可以了，缺点则是太过硬核，不适合老年人使用。 由 Mozzie 在一个知乎回答 中提供的基于 Android 无障碍服务的一键视频应用。但在试用之后发现作者基本只是写了个 Demo，几乎没有易用性，而且核心功能——一键发起视频，已经无法使用了。 最后我决定同样基于 Android 无障碍服务，开发一个简单易用的一键发起视频聊天工具。也就诞生了 QuickWeChatCall 项目。 1.4. 原理原理非常简单，就是利用 Android Accessibility Service，监听微信的 UI 变动。根据一定的步骤，寻找指定的 UI 组件，执行点击操作即可。 2. 细节2.1. 无障碍权限声明无障碍服务的权限声明需要在 AndroidManifest.xml 中声明： 1234567891011121314&lt;application&gt; &lt;service android:name="无障碍服务类名" android:label="无障碍服务名称" android:permission="android.permission.BIND_ACCESSIBILITY_SERVICE"&gt; &lt;intent-filter&gt; &lt;action android:name="android.accessibilityservice.AccessibilityService" /&gt; &lt;/intent-filter&gt; &lt;meta-data android:name="android.accessibilityservice" android:resource="@xml/accessibility_config" /&gt; &lt;/service&gt;&lt;/application&gt; 然后在 xml/accessibility_config 中声明： 12345678&lt;accessibility-service xmlns:android="http://schemas.android.com/apk/res/android" android:accessibilityEventTypes="typeAllMask" android:accessibilityFeedbackType="feedbackSpoken" android:accessibilityFlags="flagIncludeNotImportantViews" android:canRetrieveWindowContent="true" android:description="无障碍服务描述" android:notificationTimeout="100" android:packageNames="监听包名" /&gt; 这里只解释几个关键的字段 无障碍服务类名：提供无障碍服务的服务类的名称，后续细谈 无障碍服务名称：在系统设置中显示的无障碍服务的名称 无障碍服务描述：在系统设置中显示的无障碍服务的描述 监听包名：无障碍服务监听的包名，比如这里我们需要监听微信的 UI 更新，因此包名就是微信的包名 com.tencent.mm 检查无障碍服务的授权比较特殊，不像其他权限一样可以通过 Dialog 的方式提示用户授权，而是需要在系统设置的无障碍服务中手动开启。 因此最好的办法就是在启动的时候检查无障碍权限情况，如果没有得到授权就转跳到系统设置界面。 检查无障碍权限的代码，参考了 Stack Overflow 上的答案： 123456789101112131415161718192021222324252627282930private boolean isAccessibilitySettingsOn(Context mContext) &#123; int accessibilityEnabled = 0; final String service = getPackageName() + "/" + AccessibilityService.class.getCanonicalName(); try &#123; accessibilityEnabled = Settings.Secure.getInt( mContext.getApplicationContext().getContentResolver(), android.provider.Settings.Secure.ACCESSIBILITY_ENABLED); &#125; catch (Settings.SettingNotFoundException e) &#123; Log.e(TAG, "Error finding setting, default accessibility to not found: " + e.getMessage()); &#125; TextUtils.SimpleStringSplitter mStringColonSplitter = new TextUtils.SimpleStringSplitter(':'); if (accessibilityEnabled == 1) &#123; String settingValue = Settings.Secure.getString( mContext.getApplicationContext().getContentResolver(), Settings.Secure.ENABLED_ACCESSIBILITY_SERVICES); if (settingValue != null) &#123; mStringColonSplitter.setString(settingValue); while (mStringColonSplitter.hasNext()) &#123; String accessibilityService = mStringColonSplitter.next(); if (accessibilityService.equalsIgnoreCase(service)) &#123; Log.v(TAG, "***ACCESSIBILITY IS ENABLED***"); return true; &#125; &#125; &#125; &#125; Log.v(TAG, "***ACCESSIBILITY IS DISABLED***"); return false;&#125; 跳转到系统无障碍服务设置界面： 1startActivity(new Intent(Settings.ACTION_ACCESSIBILITY_SETTINGS)); 2.2. 无障碍服务当应用开启无障碍服务权限之后，注册的无障碍服务类就会在后台运行。当注册包名的 UI 发生变化是，就会触发事件，并调用无障碍服务类中相应的回调。这些事件可能是，内容变更、创建或删除节点等。 所以核心逻辑就是在无障碍服务类中，处理对应的事件。 2.3. 逻辑整个发起微信视频的步骤经过多次调整最后确定为： 打开微信 点击微信下方导航条中的“联系人” 点击联系人界面的“标签“ 点击标签列表中的”微信一键视频“标签 点击对应的微信好友 点击”视频聊天“按钮 选择”视频聊天“ 因此，程序运行的逻辑就是 打开微信，将当前步骤设定为上述步骤 2 等待 UI 更新 UI 更新后，在界面中寻找该步骤需要点击的元素，点击 将步骤设置为下一步 回到 2，重复执行，直到结束 2.4. 去抖动因为 UI 更新造成的事件可能非常密集，例如家在列表的时候，有可能每一个列表项的加入都会造成一次事件回调。而程序其实只需要在一次 UI 更新的结束阶段，寻找指定元素就可以了。所以需要一定的去抖动机制。 原理其实也非常简单，可以参照 Lodash 中的实现。 123456789101112131415161718@Overridepublic void onAccessibilityEvent(AccessibilityEvent event) &#123; if (finished) &#123; finished = false; &#125; else &#123; Log.v(TAG, "bounce"); handler.removeCallbacks(new Runnable() &#123; @Override public void run() &#123; _onAccessibilityEvent(input); finished = true; &#125; &#125;); &#125; input = event; handler = new Handler(); handler.postDelayed(runnable, WAIT);&#125; 3. 坑3.1. 无障碍服务授权期限获得无障碍服务的权限之后，无障碍服务类就在后台运行了。但如果这时候由于任何情况（关机、重启、后台被杀、自身异常等等），无障碍服务类关闭了，那么无障碍服务的权限就会自动丢失，必须重新授权。 3.2. 微信首页组件搜索无障碍服务提供了一个函数 findAccessibilityNodeInfosByText 用来搜索当前布局中的元素，但是不知为何，在微信首页调用这个函数搜索不到任何内容。然而自己手动遍历的话，却可以搜索到。 因此我手动实现了一个深度优先搜索的多属性搜索函数： 123456789101112131415161718192021222324252627private AccessibilityNodeInfo findNode(AccessibilityNodeInfo root, Property type, String text) &#123; if (root == null) return null; boolean satisfied = false; switch (type) &#123; case TEXT: satisfied = root.getText() != null &amp;&amp; text.contentEquals(root.getText()); break; case CLASS_NAME: satisfied = root.getClassName() != null &amp;&amp; text.contentEquals(root.getClassName()); break; case DESCRIPTION: satisfied = root.getContentDescription() != null &amp;&amp; text.contentEquals(root.getContentDescription()); break; &#125; if (satisfied) &#123; return root; &#125; else &#123; for (int i = 0; i &lt; root.getChildCount(); i++) &#123; AccessibilityNodeInfo result = findNode(root.getChild(i), type, text); if (result != null) &#123; return result; &#125; &#125; &#125; root.recycle(); return null;&#125; 3.3. 魅族调试在模拟器上装微信遇到一些问题，因此我就直接在手头唯一的魅蓝 5 上实机调试。但是发现在魅蓝 5 上无论如何都获取不到 Log 信息，后来发现需要在 系统设置 -&gt; 开发者选项 -&gt; 性能优化 -&gt; 高级日志输出 中选择 全部允许。 4. 后来后来由于，上面也提到的无障碍权限总是需要重复授权的问题，虽然简单开发完了这个工具，最后还是放弃了使用。毕竟对于奶奶来说，如果一不小心开关机或者清理了后台，重新授权确实太复杂了。 最后的解决方法是，FaceTime 😂 没错，Apple 大法好。通过捷径配合 FaceTime，奶奶可以在 iPad 上一键发起视频聊天。 唯一的缺点大概就是必须是对方也必须是苹果设备，恰好我和姐姐都是✌️。 感谢洛伊酱 ❤️ 提供的 iPad 呀，奶奶超开心。]]></content>
      <categories>
        <category>Development</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[随机数是如何生成的]]></title>
    <url>%2Fposts%2Fd02e%2F</url>
    <content type="text"><![CDATA[本文主要介绍随机数的概念与分类，以及简单的统计学伪随机数算法。 1. 随机数概念这里我们主要讨论的是密码学范畴的随机数。随机数的随机性检验可以分为三个标准： 统计学伪随机性。在给定的随机比特流样本中，1 的数量大致等于 0 的数量。也就是说，如果我们把一个（包含足够多随机数的）随机序列里的每个随机数数转化为二进制数，并首尾相接形成一个串，那么这个串中的 1 和 0 的数量应该大致相等。满足这类要求的数字，人类“一眼看上去”是随机的。 密码学安全伪随机性。给定一定长度的随机序列，在多项式时间内演算出随机序列的任何部分的概率低于 50%。例如即使给定随机序列的前 100 个随机数，也无法在有效地算出第 101 个随机数是什么。这样的伪随机数序列难以被预测。 真随机性。随机序列不可重现。也就是说，给定相同的参数，多次计算出的结果是不同的。由于计算机算法都具备确定性的特征，因此真随机数无法通过算法生成。 相应的，随机数被分为三类： 统计学伪随机数。仅符合第一个标准的随机数。也就是只是人类“一眼看上去”觉得随机而已。 密码学安全的伪随机数。符合前两个标准的的随机数，也就是说不仅人类觉得随机，而且随机序列难以预测。这种随机数可以通过密码学安全伪随机数生成器（ CSPRNG ）计算得出。 真随机数。同时符合三个条件的随机数，主流观点认为只有通过量子力学的内禀随机性生成的随机数才是真随机数。 2. 统计学伪随机数算法2.1. 平方取中法 Middle-square method算法描述该方法由冯 · 诺伊曼在 1946 年提出，算法非常简单： 选择一个 m 位数 $N_i$ 作为种子 计算 $N_i^2$ 若 $N_i^2$ 不足 2m 位，在前补 0。选择这个数中间 m 个位的数，即 $10^{\lfloor m/2 \rfloor}$ 至 $10^{\lfloor m/2 \rfloor + m}$ 的数，将结果作为 $N_{i+1}$。 以 675248 为种子为例，675248 的平方为 455959861504，最后取最中间的 6 位数字作为结果：959861。 简单实现Python 实现如下： 1234567seed = '675248'def middleSquare(): global seed length = len(seed) square = int(seed) * int(seed) seed = str(square).zfill(length * 2)[int(length / 2):int(length / 2) + length] return int(seed) 体验 See the Pen BGJxVE by Andie (@Andiedie) on CodePen. 问题 总体周期过短。对于 n 位数的种子，它的循环周期总是小于等于 $8^n$。 如果中间 n 位都是零，接下来就会永远输出 0。 如果种子的前半部分为 0，那么后续的随机序列很快就会变成 0。你可以尝试在上面的 Seed 位置填入0099，并点击多次 Get Next。 随机队列卡住不变。例如当种子是 0100、2500、3792、7600 时，随机序列将永远不会改变。而这只是四位数种子时的情况。 一些特殊的序列还会产生极短的周期。例如 0540 -&gt; 2916 -&gt; 5030 -&gt; 3009。事实上，00 ~ 99 这 100 个二位数种子，没有任何一个周期可以超过 14。 2.2. 线性同余方法 Linear congruential generator算法描述线性同于方法（简称 LCG ），原理如下： $X_{n+1}= (aX_n+c) \mod m$ 其中： $m$ 是模数，$m &gt; 0$ $a$ 是乘数，$0 &lt; a &lt; m$ $c$ 是增量，$0 \le c &lt; m$ $X_0$ 是种子，$0 \le X_0 &lt; m$ 线性同余方法就通过不断计算该式子，递推地算出随机序列。 需要注意的是，LCG 对参数的选择极其敏感。好的参数选择，可以使 LCG 产生的随机数队列序列拥有很长的周期，解决上述平方取中法的缺陷。但是糟糕的参数选择也会使得 LCG 的表现非常差。 一些常用的参数： 来源 模数 $m$ 乘数 $a$ 增量 $c$ C++11 的 minstd_rand0 $2^{31}-1$ 16807 0 C++11 的 minstd_rand $2^{31}-1$ 48271 0 Java 的 java.util.Random $2^{48}$ 25214903917 11 要注意的是，LCG 并不总是将计算结果的全部二进制位都作为输出。比如 Java 在每次迭代中使用 48 位进行计算，但是只返回结果中的 32 个高有效位。这是因为（统计上）使用这种截断方法可以拥有更长的周期，产生更加好的随机序列。 简单实现Python 实现如下，这里的参数使用的是与 C++11 的 minstd_rand 相同的参数 12345678seed = 1m = 2**31 - 1a = 48271c = 0def linearCongruential(): global seed seed = (a * seed + c) % m return seed 体验 See the Pen 随机数-线性同余法 by Andie (@Andiedie) on CodePen. 优缺点优点： LCG 速度快，且非常省空间（通常只需要 32 位或者 64 位）。且当周期足够大时，LCG 甚至可以通过一些严格的统计测试。 缺点： 通过线性同余方法构建的伪随机数生成器的参数可以轻易地由其输出的随机序列演算得知，所以此种伪随机数生成器属于统计学伪随机数生成器。 此外，LCG 产生的随机序列的最大周期是模数 $m$，通常是 $2^{32}$ 左右，这对于大多数场景来说已经足够了。不过对于某些应用来说，这样的周期还不够大。 2.3. 梅森旋转算法 Mersenne twister梅森旋转算法松本真和西村拓士在 1997 年开发，可以快速产生高质量的伪随机数，修正了古典随机数发生算法的很多缺陷，是 R、Python、Ruby、IDL、Free Pascal、PHP、Maple、MATLAB、GNU 多重精度运算库和 GSL 的默认伪随机数产生器。从 C++11 开始，C++ 也可以使用这种算法。 算法描述目前使用最广泛的是 MT19937，可以产生 32 位的整数序列。整个算法主要分为三个阶段： 初始化：根据种子生成初始状态。 迭代：迭代产生下一个状态。 提取：从当前状态中提取随机数。 简单实现Python 实现如下： 12345678910111213141516171819202122232425class MT19937: def __init__(self, seed = 0): self.state = [0] * 624 self.index = 0 self.state[0] = seed for i in range(1, 624): self.state[i] = (0x6c078965 * (self.state[i - 1] ^ (self.state[i - 1] &gt;&gt; 30)) + i) &amp; 0xffffffff def generate_numbers(self): for i in range(624): y = (self.state[i] &amp; 0x80000000) + (self.state[(i + 1) % 624] &amp; 0x7fffffff) self.state[i] = self.state[(i + 397) % 624] ^ (y &gt;&gt; 1) if y % 2: self.state[i] = self.state[i] ^ 0x9908b0df def extract_number(self): if self.index == 0: self.generate_numbers() y = self.state[self.index] y ^= y &gt;&gt; 11 y ^= (y &lt;&lt; 7) &amp; 0x9d2c5680 y ^= (y &lt;&lt; 15) &amp; 0xefc60000 y ^= y &gt;&gt; 18 self.index = (self.index + 1) % 624 return y 体验 See the Pen BGJxvg by Andie (@Andiedie) on CodePen. 优缺点优点： 周期非常长，MT19973 的周期可以达到 $2^{19973} - 1$。 均匀性好。 速度非常快，基本都是位运算。 缺点： 空间成本高，需要 2.5 KB 的缓存空间。（之后原作者又推出了仅占用 127 bits 的 TinyMT ） 不是密码学安全的伪随机数生成器。由于提取函数是可逆的位运算，暴露了内部状态，因此梅森旋转算法是可以爆破的。 参考 随机数. (2018, August 21). Retrieved from 维基百科, 自由的百科全书: https://zh.wikipedia.org/w/index.php?title=%E9%9A%8F%E6%9C%BA%E6%95%B0&amp;oldid=50958514 密码学安全伪随机数生成器. (2018, October 9). Retrieved from 维基百科, 自由的百科全书: https://zh.wikipedia.org/w/index.php?title=%E5%AF%86%E7%A0%81%E5%AD%A6%E5%AE%89%E5%85%A8%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%9F%E6%88%90%E5%99%A8&amp;oldid=51577215 平方取中法. (2018, April 29). Retrieved from 维基百科, 自由的百科全书: https://zh.wikipedia.org/w/index.php?title=%E5%B9%B3%E6%96%B9%E5%8F%96%E4%B8%AD%E6%B3%95&amp;oldid=49350258 线性同余方法. (2018, April 29). Retrieved from 维基百科, 自由的百科全书: https://zh.wikipedia.org/w/index.php?title=%E7%B7%9A%E6%80%A7%E5%90%8C%E9%A4%98%E6%96%B9%E6%B3%95&amp;oldid=49350290 梅森旋转算法. (2018, July 30). Retrieved from 维基百科, 自由的百科全书: https://zh.wikipedia.org/w/index.php?title=%E6%A2%85%E6%A3%AE%E6%97%8B%E8%BD%AC%E7%AE%97%E6%B3%95&amp;oldid=50644255]]></content>
      <categories>
        <category>Principle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[实训报告 2nd]]></title>
    <url>%2Fposts%2F5fe4%2F</url>
    <content type="text"><![CDATA[最近主要按照师兄的指导，读论文了解ResNet，读TensorFlow官方的ResNet实现，简单修改网络以及了解DeepFashion数据集。 1. 残差网络1.1. 理解残差网络1.1.1. The deeper, the better已经有大量实验以及实践证明，网络的层级结构越深，网络的表现就越好。 Very deep convolutional networks for large-scale image recognition 和 Going deeper with convolutions 两篇论文均表明网络的深度至关重要。 在ImageNet数据集中表现优秀的模型，都具有“非常深”的网络，深度在16到30之间。 许多重要的视觉识别任务也通过使用非常深的模型，取得了非凡的效果。 1.1.2. The deeper the network, the harder it is to train既然网络深度如此重要，那么训练出更好的网络，岂不是就和不断堆叠网络深度一样简单？ 当然不是！不断加深的网络会带来两个问题： 梯度消失/爆炸 Vanishing/Exploding Gradients 更深的网络遇到的第一个问题就是臭名昭著的梯度消失/爆炸问题，它使得网络一开始就难以收敛。不过现在这个问题很大程度上已经可以通过采用标准初始化 Normalized Initialization和中间层标准化 Intermediate Normalization解决。 退化 Degradation 虽然通过上述的方法，我们可以使数十层的网络通过随机梯度下降 SGD开始收敛 ，但是退化现象接踵而至：随着网络深度的增加，模型的准确度会在某个深度达到饱和，之后迅速下降。我们暂时把准确度饱和时的深度称为适宜深度，退化现象表现为，当网络深度超过适宜深度时，训练误差会越来越高，这也会导致更高的测试误差。如下图： 这是20层和56层的简单网络再CIFAR-10数据集上的训练误差和测试误差。可以看出，由于退化现象，更深的网络反而表现更差。 1.1.3. 残差映射 Residual Mapping通常情况下，我们正利用数个堆叠的层拟合一个目标映射$\mathcal{H}(x)$。但在深度残差学习框架 deep residual learning framework 中，我们不直接拟合目标映射$\mathcal{H}(x)$，而是这几个堆叠的层拟合另一个映射$\mathcal{F}(x) := \mathcal{H}(x) - x$。此时，目标映射被重写为$\mathcal{F}(x) + x$。 这里有一个假设：残差映射$\mathcal{H}(x)-x$比原映射$\mathcal{H}(x)$更容易优化。 那么为什么要使用残差学习？引用theone的直觉描述： 假设这个网络的目标映射是输出5，输出5.1，即$\mathcal{H}(5)=5.1$。如果直接拟合这个映射，那么可以得到一个拟合结果，函数$\mathcal{F’}(5)=5.1$。引入残差后，拟合结果的函数变为$\mathcal{F}(5)=0.1$（其中$\mathcal{H}(5)=\mathcal{F}(5)+5$ ）。 现在假设输出的要求从5.1变为了5.2，即$\mathcal{H}(5)=5.2$。那么直接拟合的函数$\mathcal{F’}(5)$从5.1到5.2变化了$1/51\approx0.2$，而引入残差的映射$\mathcal{F}(5)$从0.1到0.2变化了100%。可以看出，引入残差映射对于输出的变化更加敏感，对权重的调整作用更大。 因此，残差学习的思想可以理解为：去掉相同的主体部分，从而突出微小的变化。 1.1.4. 快捷连接 Shortcut Connections上述映射$\mathcal{F}(x)+x$由一个快捷连接实现，如下图： 在这里，快捷连接是一个恒等映射，直接被添加到整个堆叠层的输出$\mathcal{F}(x)$上，得到$\mathcal{F}(x)+x$。恒等快捷连接不仅不增加额外的参数，而且不增加计算复杂度。 公式表示为： $$y=\mathcal{F}(x, {W_i}) + x$$ 这里要求$x$与$\mathcal{F}(x)$具有相同的维度，如果维度不同，则使用简单的线性投影$W_s$来匹配维度： $$y=\mathcal{F}(x,W_i)+W_sx$$ 为什么要使用恒等映射？实际上在ResNet原团队的另一篇论文[2]中解释了这个问题。在文章中，作者设计了六种快捷连接的映射： 实验证明，恒等映射的误差衰减最快，误差也最小，其他快捷连接的形式都产生了较大的误差（有的甚至超过了20%）： 1.1.5. 构建块 Building Block像上一小节中一个残差单元的结构，被称为一个构建块 Building Block。此外还有另一种瓶颈构建块 Bottleneck Building Block： 这种构建块由三个卷积层堆叠而成，第一个和最后一个$1\times1$卷积层负责减小或恢复维度，中间的$3\times3$卷积层负责提取特征。这样的构建块通常用于更深的网络中。 1.2. 官方模型以下代码来自于TensorFlow官方给出的ResNet实现，用于训练CIFAR-10数据集。接下来将通过全部使用默认配置 情况下，了解ResNet是如何被构建的。 1.2.1. 配置解释在默认情况下，运行python cifar10_main.py，使用的是如下配置： data_dir=/tmp/cifar10_data 决定数据集的位置，这个参数对模型没有影响，不讨论。 model_dir=/tmp/cifar10_model 决定模型存储的位置，这个参数对模型没有影响，不讨论。 resnet_size=32 模型中卷积层的数量 train_epochs=250 针对整个数据集的训练次数 epochs_between_evals=10 这个参数对模型没有影响，不讨论。 batch_size=128 每次从训练集中取出的样本数 卷积层的数量第三个参数resnet_size=32表示卷积层的数量，在官方实现中，对这个数量有一个限制： 123# cifar10_main.pyif resnet_size % 6 != 2: raise ValueError('resnet_size must be 6n + 2:', resnet_size) 也就是说，卷积层的数量必须是6n+2。为什么有这样的限制呢？ 首先解释6n。通过阅读ResNet的论文[1]，我们可以知道，有两种构建块——普通的构建块具有两个卷积层、瓶颈构建块具有三个卷积层。 假设我们只使用具有两个卷积层的普通构建块，那么只需要要求卷积层满足2n即可，因为每个构建块有两个卷积层，构建块是不可分的，所以有n个构建块则表示有2n个卷积层，这很好理解。同样的道理，如果我们只使用有三个卷积层的瓶颈构建块，则要求卷积层有3n个。 但由于官方的ResNet同时支持使用两种构建块，为了实现这一点，就只能找2n和3n的最小公倍数——6n。 接着解释为什么要+2。通过上面的解释，可以得出一个结论：6n这个数量表示的是构建块中卷积层的总数。而+2自然得就可以看做是网络中其他部分的卷积层总数，查看源码，可以看到这两段： 12345678910111213141516# resnet_model.py# 构建块之前的卷积，用于维度转换inputs = conv2d_fixed_padding(...)...# 构建块for i, num_blocks in enumerate(self.block_sizes): num_filters = self.num_filters * (2**i) inputs = block_layer(...)...# 构建块之后的平均池化# 平均池化是卷积的一种inputs = tf.layers.average_pooling2d(...) 从代码可以看出，除了在构建块的前后分别有一次用于维度转换的卷积核一次平均池化（卷积的一种），这就是+2的来源。 因此可以得出，在这种实现中卷积层数数量一定满足6n+2。 其他参数另外另个值得一提的参数是train_epochs和batch_size。前者指的是对于整个训练集，模型进行训练的次数；后者则表示，每次从训练集中取出的样本数。 可以很简单的得到一个公式，计算总的训练步数： $$step = \frac{train_epochs\times dataset_size}{batch_size}$$ 将默认数据，train_epochs=250、batch_size=128以及CIFAR-10的训练集大小dataset_size=50000带入可以算出，step=97656.25。 实际的训练情况如下： 题外话可以通过日志看到，在GeForce GTX 1080上，训练速度大概如下（大概20step/s）： 所以总的训练时间大概是97656/20=4882秒，大概一个半小时。 1.2.2. 网络结构1) 残差结构之前输入先搞清楚整个网络的输入。输入来自CIFAR-10的训练集，在这个实现中，图片被进行了多次预处理（包括随机剪裁、随机镜像反转、标准化等），最后形成了$3\times32\times32$的矩阵，或者写成[3, 32, 32]，对应[channels, width, height]。实现中还处理了channels_last和channels_first的问题，这里为了方便就认为所有输入图片都是channels_first。此外，每次从数据集中取出的是batch_size=128张图，所以实际上的输入矩阵为[128, 3, 32, 32]，对应[batch, channels, width, height]。 网络中使用的卷积网络中并不是直接使用TensorFlow的卷积实现，而是定义了一个名为conv2d_fixed_padding的卷积操作。逻辑如下： 如果strides=1，则通过padding保证卷积前后size一致 如果strides&gt;=1，则通过padding使得卷积后的特征图的size变为$\lceil \frac{size}{strides} \rceil$ 通过读源码可知，实际上是通过padding将kernel_size的影响抵消，过程比较繁琐就不写出来了。 举个简单的例子，如果输入为[128, 3, 32, 32]，卷积核数量为16 strides=1，输出位[128, 16, 32, 32]，size依旧为32*32 strides=3，输出位[128, 16, 11, 11]，其中$11 = \lceil \frac{32}{3} \rceil$ 在之后的描述中，所有的卷积都指的是conv2d_fixed_padding。 第一次卷积来自训练集的输入[128, 3, 32, 32]在这里经历了第一次卷积，参数如下： strides = 1 filters = 16 kernel_size = 3 这次卷积的目的主要是进行维度的转换，卷积的的结果是[128, 16, 32, 32]。 最大池化实现中实际上定义了最大池化的操作，但是由于默认配置下，这个操作并不会被执行，所以这里忽略它。 残差层之前总结 2) 残差结构这是网络的重点，整个残差结构分为多个残差层，每个残差层分为多个构建块，每个构建块呢有多个卷积层，每个卷积层内有多个卷积核。下面将逐一进行介绍。 残差层在一个残差结构中，有多个残差层。我们采用默认配置的情况下，有三个残差层。 实际上在官方实现的ResNet中，残差层被固定为3层： 123456# cifar10_main.pysuper(Cifar10Model, self).__init__( ..., block_sizes=[num_blocks] * 3, block_strides=[1, 2, 2]) 这是构建模型时的代码，其中block_sizes和block_strides的长度就是残差层的数量，被固定为了3层。 每个残差层内部，特征图的维度是一致的，但是在残差层之间特征图维度不同。 构建块每个残差层内部有多个构建块，我们采用默认配置的情况下，每个残差层有5个构建块。 1234567# cifar10_main.pynum_blocks = (resnet_size - 2) // 6super(Cifar10Model, self).__init__( ..., block_sizes=[num_blocks] * 3, block_strides=[1, 2, 2]) 同样是这段代码，其中num_blocks代表每一层中构建块的数量，可以看出是通过卷积层的数量resnet_size计算出来的。默认情况下resnet_size=32，所以num_blocks=5，每个残差层有5个构建块。 从上文我们可以知道，论文[1]中构建块共有两种实现，分别为普通构建块v1和瓶颈构建块v1，在另一篇论文[2]中，这两种构建块有不同的实现——普通构建块v2和瓶颈构建块v2。v1和v2两种实现的主要区别是：BN层是在卷积操作之前执行还是之后执行，具体可以见论文[2]。在这四中构建块中，根据默认配置： 123456# cifar10_main.pyDEFAULT_VERSION = 2super(Cifar10Model, self).__init__( ..., bottleneck=False) 可以得出，使用的是普通构建块v2。 卷积层和卷积核由上图，每个构建块都由两次卷积操作构成，每次卷积操作之前都会进行BN和ReLU，最后叠加一个快捷连接的恒等映射，得出结果。也就是说，每个构建块中有两个卷积层。 第一个卷积层中的每个卷积核的参数如下： 第一个残差层中：strides=1、kernel_size=3、filters=16 第一个残差层中：strides=2、kernel_size=3、filters=32 第一个残差层中：strides=2、kernel_size=3、filters=64 其中strides和kernel_size是在再如下代码中定义： 123456# cifar10_main.pysuper(Cifar10Model, self).__init__( ..., kernel_size=3, block_strides=[1, 2, 2]) filters则通过以下代码定义： 123456789# cifar10_main.pysuper(Cifar10Model, self).__init__( ..., num_filters=16, block_sizes=[num_blocks] * 3)# resnet_model.pyfor i, num_blocks in enumerate(self.block_sizes): num_filters = self.num_filters * (2**i) 可以看出，在每个残差层，filters数量都会加倍。 卷积代码： 1234inputs = conv2d_fixed_padding( inputs=inputs, filters=filters, kernel_size=3, strides=strides, data_format=data_format) 第二个卷积层中的卷积核，参数与第一层中的基本一致，唯一的区别是，所有的卷积核的strides=1。 1234inputs = conv2d_fixed_padding( inputs=inputs, filters=filters, kernel_size=3, strides=1, data_format=data_format) 残差层之间的投影由于残差层之间，输入和输出存在维度不同的问题，所以每个残差层的第一个构建块都需要进行投影。 12345678910111213# 投影函数def projection_shortcut(inputs): return conv2d_fixed_padding( inputs=inputs, filters=filters_out, kernel_size=1, strides=strides, data_format=data_format)# 每个残差层的第一个构建块进行投影inputs = block_fn(inputs, filters, training, projection_shortcut, strides, data_format)# 其余的构建块不需要投影for _ in range(1, blocks): inputs = block_fn(inputs, filters, training, None, 1, data_format) 结果 经过残差结构之后，输入和输出情况如上图。 3) 残差结构之后残差结构之后就是简单的BN层、ReLU层、平均池化层和全连接层： 4) 总体网络结构 题外话PPT是世界上最好用的作图工具23333，上图的PPT源文件链接 1.3. 修改官方模型得益于官方模型高可用的实现，对这个模型进行简单修改非常简单： 增减卷积层/残差结构：在运行时加入参数--resnet_size=m，这里m就是卷积层的数量，必须满足m % 6 == 2。可以得出整个网络中构建块的数量为block_num = (m - 2) // 2。最终卷积层的数量实际上的与你采用什么构建块有关，如果使用普通构建块，则卷积层数量为block_num * 2，如果采用瓶颈构建块则为block_num * 3。 使用不同的构建块：默认使用的是普通构建块v2，可以通过修改resnet_model.py中的DEFAULT_VERSION使用不同的版本；通过修改cifar10_main.py中的bottleneck=True使用不同的构建块。 训练不同的数据集：网络的结构不需要过多的修改，主要修改的是cifar10_main.py数据输入的处理函数： get_filenames parse_record preprocess_image input_fn get_synth_input_fn 以及修改一些全局变量： _NUM_CLASSES 2. DeepFashion2.1. 简介DeepFashion是一个关于服饰的超大规模数据集，具有以下特点： DeepFashion拥有超过800,000张时尚服饰图片，包括良好的店铺图片和消费者拍摄的不受约束的图片。 DeepFashion拥有50个分类（categories）、1000中属性（attributes）以及服饰关键点（clothing landmarks）。 DeepFashion拥有超过300,000对交叉/跨域的服饰图，例如同一个服饰来自商家和消费者的一对图片。 此外，DeepFashion还有五个基准测试问题（Benchmark），包括：类别和属性预测、店铺服饰检索、消费者对店铺服饰检索、服饰关键点检测和综合测试。 2.2. 基准测试问题DeepFashion目前有五个基准测试问题： 类别和属性预测 Category and Attribute Prediction Benchmark，这项任务是对50个类别和1,000个属性进行分类。 店铺服饰检索 In-shop Clothes Retrieval Benchmark，这个任务是确定源自店铺拍摄的两幅图片是否属于相同的服饰。 消费者对店铺服饰检索 Consumer-to-shop Clothes Retrieval Benchmark，这项任务是将来自消费者图片与来自店铺的相同服饰的图片进行匹配。 服饰关键点检测 Fashion Landmark Detection Benchmark，这项任务是预测服饰上关键点的位置，例如领口，下摆和袖口的位置。 综合测试 Fashion Synthesis Benchmark，这项任务是利用已有的图片生成新的图片。 2.2. 店铺服饰检索2.2.1. 图片In-shop Clothes Retrieval Benchmark的图片格式为： 居中的256*256 JPG格式图片 原始图像的纵横比保持不变 2.2.2. 标注In-shop Clothes Retrieval Benchmark的数据集中标注如下： 图片中服饰的边界盒 list_bbox_inshop.txt，第一行为数量，第二行为列名 图片名，如img/WOMEN/Blouses_Shirts/id_00000001/02_1_front.jpg 服饰类型 | 值 | 意义 || —- | ———- || 1 | upper-body || 2 | lower-body || 3 | full-body | 姿势类型 | 值 | 意义 || —- | —————- || 1 | frontal view || 2 | side view || 3 | back view || 4 | zoom-out view || 5 | zoom-in view || 6 | stand-alone view | 边界盒位置 | 符号 | 意义 || ——– | —————– || x_1, y_1 | upper left point || x_2, y_2 | lower right point | 图片中服饰的关键点 list_landmarks_inshop.txt，第一行为数量，第二行为列名 图片名，如img/WOMEN/Blouses_Shirts/id_00000001/02_1_front.jpg 服饰类型 | 值 | 意义 || —- | ——————— || 1 | upper-body，6个关键点 || 2 | lower-body，4个关键点 || 3 | full-body，8个关键点 | 变化类型 | 值 | 意义 || —- | ————– || 1 | normal pose || 2 | medium pose || 3 | large pose || 4 | medium zoom-in || 5 | large zoom-in | 关键点可见性 | 值 | 意义 || —- | —————— || 1 | visible || 2 | invisible/occluded || 3 | truncated/cut-off | 关键点 | 服饰类型 | 数量 | 意义 || ——– | —- | ———————————————————— || 1 | 6 | left collar, right collar, left sleeve, right sleeve, left hem, right hem || 2 | 4 | left waistline, right waistline, left hem, right hem || 3 | 8 | left collar, right collar, left sleeve, right sleeve, left waistline, right waistline, left hem, right hem | 服饰ID集合 list_item_inshop.txt，第一行为数量 ID，如id_00000001 服饰描述 list_description_inshop.json ID，如id_00000001 颜色，如Cream 描述，如Style Deals - When temps start to rise... 属性集合 list_attr_cloth.txt 第一行位属性数量，第二行为列名 属性名，如lightweight 服饰属性 list_attr_items.txt 还有若干个值，数量等于属性集合中属性的数量 | 值 | 意义 || —- | —————— || 1 | 服饰有对应的属性 || 2 | 服饰没有对应的属性 | 映射关系 list_eval_partition.txt，第一行为数量，第二行为列名 图片名，如img/WOMEN/Dresses/id_00000002/02_1_front.jpg 物品ID，如id_00000002 状态 | 值 | 意义 || ——- | ————– || train | training image || query | query image || gallery | gallery image | 图片中服饰的颜色 list_color_cloth.txt，第一行为数量，第二行为列名 图片名，如img/WOMEN/Blouses_Shirts/id_00000001/02_1_front.jpg 颜色，如Cream 2.2.3. 对标注的理解 3. 参考[1]Deep Residual Learning for Image Recognition [2]Identity Mappings in Deep Residual Networks [3]知乎|theone的回答 [4]DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations [5]Fashion Landmark Detection in the Wild]]></content>
      <categories>
        <category>Homework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SyncMyCookie 中文文档]]></title>
    <url>%2Fposts%2Fabbd%2F</url>
    <content type="text"><![CDATA[SyncMyCookieEnglish | 中文 SyncMyCookie 是一个可以在多个浏览器间同步Cookie的插件。 你可以使用它同步任意网站的 cookies。你还可以通过配置自定义 Auto Merge 和 Auto Push 的规则。 1. 安装 推荐：Chrome Web Store SyncMyCookie.crx 预编译 在 Chrome 扩展（chrome://extensions）中启动开发者模式并通过加载未打包的拓展安装。 从源码编译 1234git clone https://github.com/Andiedie/sync-my-cookie.gitcd sync-my-cookieyarn # npm installyarn build # npm run build 像上面一样加载build目录即可。 2. 使用场景2.1. 避免频繁登录有些网站设置的 cookies 是 session 级别的，一旦浏览器关闭，这些 cookies 就会过期失效，这使得我们需要频繁地进行登录。 你可以在登录有使用 SyncMyCookie 保存这些 cookies，并启动 Auto Merge 功能。这样即使浏览器关闭了，你的登录状态也不会失效。 2.2. 共享账号也许你会有这样的需求： 与朋友共享账号 突破单点登录的限制 在多个浏览器间同步登录状态 使用 SyncMyCookie 能非常简单的满足这些需求。 你只需要在登录后使用 SyncMyCookie 保存网站的 cookies，并启动 Auto Push 功能；在其他的浏览器上，启用 Auto Merge 功能。这样你的登录状态就可以在多个浏览器间自动同步。 3. 配置为了能在设备间同步 cookies，插件将你的 cookies 加密存储在 GitHub Gist 中，这就要求你有一个 GitHub 账号。 如果发现了一些更好的存储方案，请在这里提交 issue 告诉我，十分感谢。 3.1. 生成 GitHub Access TokenGitHub Access Token（以下简称 token）的作用是让插件有权限修改你的 Gist。你可以在这里生成一个新的 token。 注意： 插件只需要 Gist 权限，所以请不要勾选其他不必要的权限，以保证你的账号安全。 3.2. 配置插件 右键插件，点击选项。 输入你的 token 和加密密钥。 请注意：忽略可选的 Gist ID 和 Filename 字段之后，插件会创建一个全新的 Gist 来存储数据。如果你想要在两个浏览器间同步 cookies，那么两个浏览器上的插件必须拥有相同的配置，即 GitHub Access Token、password、Gist ID 和 Filename 这四个字段必须完全相同。插件提供了导入导出配置的功能帮助你完成这项工作。 4. 使用4.1. Push cookies将指定网站 cookies 加密保存到 Gist 中，只需要在浏览该网站时点开插件，点击 Push 即可。 4.2. Merge cookeis要使用以保存的 cookies，在插件上选择对应的网站并点击 Merge 即可。 4.3. Auto Merge当指定网站开启 Auto Merge 后，每当打开浏览器，插件都会自动将指定的 cookies 合并进浏览器。 自动合并后，插件上会有标徽展示本次自动合并的网站数量： 4.4. Auto Push当指定网站开启 Auto Push 后，每当该网站的 cookies 发生变化，插件都会自动推送新的 cookies。 自动推送后，插件上会有标徽展示本次自动推送的网站数量： 配置 Auto Push通常，cookies 中只有部分值是比较重要的。通过配置，Auto Push 功能可以在指定的值发生变化后才进行自动推送。 将鼠标悬停在 Push 图标上，点击出现的配置按钮： 选择或输入名称，表明当这些名称的 cookies 变化时，进行推送。 5. 安全由于 cookies 是你非常重要的安全凭证，所以请非常小心地使用这个插件。 插件使用 HTTPS 和 AES-128-CBC 保证在传输和存储过程中，你的 Cookie 是安全的，但你仍然需要注意如下几点： 因此为了保证你的 cookies 安全，请不要随意透露你的配置，特别是密码。一旦配置泄露，你的 cookies 也随之泄露。 插件保证只会使用 GitHub Access Token 的 Gist 权限。为了防止潜在的安全问题，在生成 token 时，请只给与 Gist 权限。 理论上，多个设备使用相同的 Cookie 可以实现同时使用一些服务，但是这和服务提供商的检测机制有关。因此使用这个插件进行账号共享，风险是不确定的。]]></content>
      <categories>
        <category>Development</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用Travis进行持续集成]]></title>
    <url>%2Fposts%2F53ad%2F</url>
    <content type="text"><![CDATA[1. 持续集成1.1. 持续集成的概念 Continuous Integration is a software development practice where members of a team integrate their work frequently, usually each person integrates at least daily - leading to multiple integrations per day. Each integration is verified by an automated build (including test) to detect integration errors as quickly as possible. Many teams find that this approach leads to significantly reduced integration problems and allows a team to develop cohesive software more rapidly. ——Martin Fowler Martin Fowler关于持续集成的完整文章，可以从这里获取。 1.2. 持续集成的要素 统一的代码库 自动构建 自动测试 每次代码提交后都会触发一次构建 可以很容易地获取最新可执行的程序 自动化部署 现在使用Travis CI我们可以很容易的实现持续集成。 2. 使用Travis CI 实现自动测试Travis CI是在软件开发领域中的一个在线的，分布式的持续集成服务，用来构建及测试在GitHub托管的代码。Travis只能在GitHub项目上使用，只要项目有改动，Travis就会为其提供一个运行环境，执行测试、构建甚至部署任务。下面将演示如何配置Node.js项目的自动测试。 2.1. 为项目开启Travis进入Travis，使用GItHub账号登录，点击右上角的头像，进入Profile。选择项目，打开开关即可。 2.2. 基本配置点击项目名和开关之间的齿轮可以进入设置页，在这里你可以进行相关的配置，不过大多数情况下保持默认即可。 2.2.1. 基础设置 建议打开Build only if .travis.yml is present可以避免在没有配置文件的时候进行无意义的构建工作。此外也可以配置是否对分支、PR进行构建，并限制并行数量。 2.2.2. 自动取消 建议开启，开启后如果队列中积压了大量的构建任务（比如一次性提交了大量的commit），那么Travis只会对最新的commit进行构建，避免过长的等待时间。要注意的是，自动取消只会对等待中的任务生效，也就是说，如果你的任务正在运行，那么即使有更新的任务出现，当前任务也不会被取消。 2.2.3. 环境变量与计划任务在这里你可以定义任务中可以随时使用的环境变量，在本文的后续内容中也会有环境变量的简单使用。 此外，你还可以设置计划任务，让Travis定时对你的项目进行测试和构建。 2.3. 编写.travis.yml首先假设你的node.js项目已经编写完成，并且可以通过npm test运行测试命令。 在项目根目录，创建文件.travis.yml .travis.yml12345language: node_jsnode_js:- '9'install: npm installscript: npm test 这个配置文件描述了Travis将如何工作。首先我们将语言选定为了node.js并指定node.js的版本号为9.x.x，当然你可以指定多个版本号，Travis将在每个版本中都对你的代码进行构建和测试。 此外我们还定义了两个过程：install和script，它们分别告诉了Travis如何安装依赖，如何进行测试。 将这个文件推上GitHub，登录Travis，你会发现它正在自动的为你的项目进行构建、下载依赖并进行测试。如果测试通过，测试结果在GitHub的上有相应的标注。 至此，我们就利用Travis完成了自动测试，你在项目中的每一次改动，包括commit、branch和pull request，Travis都会按照.travis.yml的配置进行测试。 2.4. 生命周期除了上述的install和script，Travis还提供了大量的钩子函数 install：依赖安装 script：测试（如果install失败则不运行） deploy：部署（如果script失败则不运行） before_install：install之前运行 before_script：script之前运行 after_failure：script失败后运行 after_success：script成功后运行 before_deploy：deploy之前运行 after_deploy：deploy之后运行 after_script：在整个过程的最后执行 完整的构建生命周期如下： 123456789before_installinstallbefore_scriptscriptafter_success or after_failurebefore_deploydeployafter_deployafter_script 生命周期中的每一个钩子函数都可以定义多个脚本，例如 123install:- command1- command2 此时当执行到install阶段时，install中的每一个命令都会被执行。且即使command1失败了，command2也会被执行。如果希望command1失败后不执行command2，可以用以下方法： 1install: command1 &amp;&amp; command2 3. 使用Travis CI 实现自动部署自动测试完成后，我们希望将测试通过的版本自动部署到服务器上。基本的思路是，让Travis登录服务器，并在服务器上运行部署脚本。 3.1. Travis登录服务器假设服务器地址是1.2.3.4。最简单的方法就是使用SSH Key登录。 3.1.1. 生成SSH Key具体可见通过SSH Key登录Linux，这里只展示简单的命令： 12345# 生成key和key.pub两个文件ssh-keygen -f key# 将公钥上传到服务器ssh-copy-id -i key.pub user@1.2.3.4 3.1.2. 配置将当前目录下的key文件复制到项目根目录中 .travis.yml1234567891011121314151617language: node_jsnode_js:- '9'addons: ssh_known_hosts: 1.2.3.4install: npm installscript: npm testbefore_deploy:- eval "$(ssh-agent -s)"- chmod 600 key- ssh-add keydeploy: provider: script script: ssh -i key user@1.2.3.4 这样我们就可以让Travis登录上我们的服务器，但是如果项目是在GitHub上开源的，那么相当于登录服务器的私钥也公开了，这当然是不可接受的。因此，我们将使用一种更加安全的方法。 3.2. 更加安全地登录服务器为了避免私钥公开，我们可以使用Travis的加密方法对私钥进行加密。 3.2.1. 下载Travis命令行工具查看这里了解如何安装Travis，由于Windows环境比较复杂，推荐使用linux环境，Windows用户可以使用WSL（WSL相关教程见WSL安装与SSH配置）。 运行下列命令安装Travis CLI 12345678# 安装rubysudo apt install ruby ruby-dev# 安装travisgem install travis -v 1.8.8 --no-rdoc --no-ri# 测试travis version# &gt; 1.8.8 3.2.2. 登录Travis12345# 登录Travistravis login# 确认登录travis whoami# &gt; You are xxx 3.2.3. 加密私钥文件现在我们假设私钥文件key和.travis.yml都处于项目根目录 12345# cd到key所在的目录（比如项目根目录）cd path/to/key# 加密文件travis encrypt-file key --add 加密完后，当前目录下会增加一个key.enc文件，即key加密后的文件。请注意，不要将key上传到GitHub，取而代之的是key.enc。 另外进入Travis网站中，项目的设置页面，可以看到新增的环境变量 并且.travis.yml中会增加一行这样的配置 .travis.yml12before_install:- openssl aes-256-cbc -K $encrypted_57510f08f3ae_key -iv $encrypted_57510f08f3ae_iv 这里$xxxx就是引用了环境变量，并使用openssl对私钥文件进行解密。 3.3. .travis.yml配置.travis.yml123456789101112131415161718192021222324language: node_jsnode_js:- '9'install: npm installscript: npm testaddons: ssh_known_hosts: 119.29.252.110before_deploy:- openssl aes-256-cbc -K $encrypted_57510f08f3ae_key -iv $encrypted_57510f08f3ae_iv -in deploy_rsa.enc -out deploy_rsa -d- eval "$(ssh-agent -s)"- chmod 600 key- ssh-add keydeploy: provider: script script: bash deploy.sh skip_cleanup: true on: branch: master 注意到这里我们新增了几行： before_deploy中的第一个命令是用于解密私钥文件key skip_cleanup是为了避免部署阶段一些文件被清除，具体可以参阅官方文档 on branch master这里是指定了只有master分支上的改动才需要进行部署 bash deploy.sh请见下一节 3.4. 编写部署脚本为了便于管理，我们让deploy阶段运行我们的部署脚本deploy.sh，那么该如何编写这个脚本呢？ 非常简单： 123456ssh -i key user@1.2.3.4 &lt;&lt; eeooffcommand1command2eeooff 按照上面的格式，将需要再服务端上运行的命令放在两个eeooff中间即可。]]></content>
      <categories>
        <category>Homework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[实训报告 1st]]></title>
    <url>%2Fposts%2Fc31d%2F</url>
    <content type="text"><![CDATA[最近主要通过阅读论文的方式，学习了卷积神经网络的基本概念、结构、方法。这篇周报主要是对所学知识的一些总结。 如果有错误，烦请在评论区指正。 1. 神经网络1.1. 神经元 Neuron神经网络由神经元组成，单个神经元的结构如下 实际上是，输入向量$x$经过权值$W$进行线性变换之后得到$W^Tx+b$，再进过激活函数$f$将线性结果转变为非线性的结果$f(W^Tx+b)$，即 $H_{W,b}=f(W^Tx+b)$，其中$W^T$是$W$的转置。 1.1.1. 神经元与神经细胞为了方便，我将用神经元来表示本文中神经网络的基本单位，而用神经细胞表示生物学中的概念。 让我们来将这个神经元与神经细胞做对比。 神经细胞有树突、细胞体和轴突。单个神经细胞可以看做一个二元分类器————兴奋时输出1，抑制时输出0。当信号量超过某个阈值时，神经元可以将兴奋沿着轴突传递给神经元。 而这里的神经元则是为了模拟神经细胞，权值向量$W$对应树突，偏置$b$对应阈值，激活函数$f$对应细胞体。神经元通过权值向量$W$接收来自上一次的输入向量$x$，并将输入$W^Tx+b$交给激活函数$f$。激活函数将决定传递给下一层神经元的输出。 1.1.2. 激活函数 Activation Function激活函数定义了神经元在线性变换$W^Tx+b$之后的非线性输出结果。 为什么使用激活函数如果不使用激活函数，由于所有的操作都是线性的，所以整个神经网络只是一个线性回归模型。线性回归模型的表达能力有限，它在很多问题上都表现得不够好，甚至无法解决这些问题。因此我们通过引入激活函数，为神经网络引入非线性的因素，增强它的能力，使其可以学习更加复杂的数据，表达输入输出之间非线性的复杂映射关系。 常用的激活函数有 Sigmoid：$S(t)=\frac{1}{1+e^{-t}}$ Tanh: $tanh(x)=\frac{sinh(x)}{cosh(x)}=\frac{e^x-e^{-x}}{e^x+e^{-x}}$ ReLU：$f(x)=max(0,x)$ 由于梯度消失问题(Vanishing Gradient Problem)，前两者已经弃用，ReLU是主流的激活函数。 1.1.3. 全连接 Fully-Connected这里我们展示的神经元，将来自输入向量$x$中的所有数据都用于计算，我们还称这个神经元是全连接的(fully-connected)。 继续我们神经元与神经细胞的比较联想，假如这个神经元是输入向量之后的第一层神经元，那么你可以想象成，我们脑中有一个树突极其巨大的神经细胞，它将来自外界的刺激全部收入囊中，并根据刺激给出输出。 全连通的好处显而易见，每个神经元都可以获取最全面的输入；但它的缺点也显而易见————我们定义处理大量的权值参数。这个缺点的具体描述，以及全连通缺点的方法，都会在接下来的内容中提到。 1.2. 多层神经网络当多个神经元组合起来，形成分层结构时，就形成了神经网络。 其中 $a_1^{(2)}=f(W^{(1)}_{11}x_1+W^{(1)}_{12}x_2+W^{(1)}_{13}x_3+b^{(1)}_1)$ $a_2^{(2)}=f(W^{(1)}_{21}x_1+W^{(1)}_{22}x_2+W^{(1)}_{23}x_3+b^{(1)}_2)$ $a_3^{(2)}=f(W^{(1)}_{31}x_1+W^{(1)}_{32}x_2+W^{(1)}_{33}x_3+b^{(1)}_3)$ $H_{W,b}=f(W^{(2)}_{12}a_1^{(2)}+W^{(2)}_{22}a_2^{(2)}+W^{(2)}_{32}a_3^{(2)}+b^{(2)}_1)$ 这里的$W_{\beta\gamma}^{(\alpha)}$表示从第$\alpha$层到第$\beta$层的第$\gamma$个神经元的权值向量$W$（为了简化，这里省略了转置符号$^T$），$b^{(\alpha)}_\beta$表示从第$\alpha$层到第$\beta$层的偏置$b$。 这是一个典型的三层神经网络，我们将Layer 2称为隐藏层(Hidden Layer)。一个神经网络中可以拥有多个隐藏层。 1.2.1. 前馈神经网络 Feedforward neural network像这样，在神经网络内部，输入从输入层向输出层单向传播，不构成任何有向环的结构，我们称之为前馈神经网络。 1.2.2. 反向传播 Backpropagation下一个要解决的问题是，怎样合理地确定神经网络中各层的权值。这句需要用到反向传播算法。 反向传播算法是训练神经网络的常用方法，该方法利用链式法则对网络中的所有权值计算损失函数的梯度，用来更新权值以最小化损失函数，本质上是一种梯度下降法。 反向传播算法有两个阶段：激励传播和权值更新 激励传播 前向传播：输入进入神经网络并前向传播，最后产生输出。 反向传播：通过损失函数求出输出与标准输出之间的误差，然后通过链式法则求出每一层的权值参数对整体误差的影响（即总误差对权值参数求偏导）。 权值更新 将输入带入前面的求到结果中，获得权值梯度。 将权值乘上一个负的学习率，加到现有的权值上，以更新它的值。 具体实例在这篇博客中有非常详细的过程。 1.2.3. 问题在前面我们就曾提到过，在我们现在介绍的神经网络中有一个由于全连接导致的巨大问题————参数数量巨大。 想象一下，假如输入是1000X1000的灰度图片（一个channel），也就是一个$10^6$个值，第二层隐藏层有$10^6$个神经元，那我们将面临$10^{12}$次方个权值。这样的参数数量是不可接受的。因此我们需要想一个办法去解决这个问题。 2. 卷积神经网络2.1. 局部连接 Locally Connected人对外界的认知是从局部到总体的，我们总是先对图像中的细节————例如边缘、颜色等有了认识，逐渐辨别轮廓，最后识别出物体。另外一个直觉的想法是，图像中的像素点总是和邻近的点关系密切，和距离较远的点关系较小甚至没有关系。 也就是说，一个单一的神经元没有必要对整个输入图像进行感知（全连接）。神经元只需要对局部进行感知（局部连接），再由更高层的神经元进行综合即可。 如上图，第二层隐藏层中的神经元只将部分值当做输入，最后由第三层隐藏层进行全连接。 回到之前的假设，假如输入依旧是1000X1000的灰度图片，第二层隐藏层依旧有$10^6$个神经元。但此时利用局部连接，第二层的神经元每个值对应输入中10X10的图像范围，那么每个神经元只需要100个权值。此时权值总数就是$10^8$个，远小于$10^{12}$个。 2.2. 参数共享 Shared Weights$10^8$个权值参数虽然对比$10^{12}$已经是相当大的进步，但我们仍然可以进一步缩小它，解决的方案就是参数共享。 第二层的$10^6$个神经元均采用不同的参数，设想一下，加入它们都采用一样的100个权值参数，那么参数的总数就只剩下了100。 我们可以这样理解权值共享，这100个参数其实是通过卷积提取图片的特征的方式。在没有权值共享之前，每个神经元提取特征的方式都是不同的（因为它们的权值参数不同）。而现在所有神经元共享这100个参数，那所有的神经元就会以相同的方式提取图片特征。又因为上述局部连接的存在，每个神经元提取特征的位置是不一样的。最终导致的结果是，每个神经元在各自的局部，用相同的方式提取特征。 这100个参数实际上是10X10的矩阵，我们将这个矩阵成为卷积核(Kernel)，卷积(Convolution)的过程就是这个卷积核在图片上游走，将覆盖范围内的所有输入值与卷积核对应位置的权值相乘累加。重复这个过程直到提取出特征图(Feature Map)，如下图所示。 2.2.1. 对灰度图像卷积对于一个图像，每个像素点由RGB三个值描述，也就是说一个图像是一个三维矩阵。我们将这三个维度分别称为长、宽和通道。 对于一个卷积核，也有三个维度，分别为长、宽和深度。 一次卷积操作有多个参数需要考虑： Size：每个卷积核的大小 Width*Height*Depth。 Stride：卷积核每次移动的步长。 Padding：卷积核在遇到边缘时补0的宽度。 现在我们考虑比较简单的情况，灰度图像的特点是，只有一个通道，那么按照上述要求，卷积核的深度只需要为1就行了。 下图展示了一个Size为3X3X1的卷积核在Stride为2、Padding为1情况下，对一个5X5X1灰度图像的卷积操作： 2.2.2. 对多通道图像卷积对于多个通道的图像，则要求卷积核的深度必须与输入图像的通道数一致。对于RGB三通道图像，则要求卷积核的深度必须为3。 下图展示了一个Size为3X3X3的卷积核在Stride为2、Padding为0的情况下，对一个9X9X3的RGB图像的卷积操作： 2.2.3. 计算特征图的大小由于卷积核的深度总是与输入图像的通道数一致，所以输出的特征图总是一个二维矩阵，我们可以通过下面的公式计算出特征图的大小： $$W_{new}=\frac{W_{old}+Padding*2-W_{kernel}}{stride}+1$$ 这里W代表Width，同理可以计算出Height。 2.3. 多核卷积我们知道，一次卷积操作生成的特征图，是利用一个卷积核提取出来的一种特征。为了能够增加特征的数量，我们可以使用多个卷积核Size、Stride、Padding完全相同，但参数不同的卷积核对输入图像进行卷积。 下图展示了我们使用两个卷积核的卷机操作： 可以发现，输出的特征图的通道数，与输入图像的通道数无关，而是与卷积核的数量有关。使用的卷积核的数量越多，我们提取的特征数量就越多，特征图的通道数也越多。 2.4. 多层卷积图像是以像素点为单位作为输入的，隐藏层对输入卷积，提取出局部特征（比如边缘）。接下来的下一个隐藏层又以之前隐藏层的输出作为输入进行卷积，提取出抽象等级更高的特征（比如轮廓）。最后不断地增加隐藏层的数量，不断提取抽象等级更高的特征。最后进行全连接，使得学习的特征具有全局化的特性。 2.5. 过拟合 Overfitting一般一个机器学习算法在训练集上训练，最后训练出来的模型被期望在用于预测时也拥有良好的表现，我们称之为泛化性。 然而如果一个模型开始学习训练集数据中的特化性质或者随即特征，在预测时对于未知数据的表现就会变差，我们称之为过拟合。 举一个简单的例子是，如果一个神经网络被训练用于分辨出所有的轿车。泛化性良好的情况下，模型只学习了轿车的通用特征，比如拥有四个轮子、车大灯、后备箱等。但如果我们的训练集中所有的轿车都是白色的，模型过度学习认为只有白色的才是轿车，这就是过拟合现象。 2.5.1. 池化 Polling通过卷积获得特征之后，我们希望使用这些特征去分类。理论上，我们可以使用提取到的所有特征去分类，但这样会面临极其大的数据量。 例如对于一个96X96X1的输入图像，我们使用一400个8X8的卷积核进行卷积（Stride为1、Padding为0），那么我们最终会得到一个89X89X400的特征图。这个特征图中拥有超过三百万个数据，如此庞大的数据量难以学习，且容易出现过拟合的现象。我们可以选择池化来解决这个问题。 所谓池化，就是尝试使用一个更小的特征图去描述一个巨大的特征图。就像我们人类观察一个巨大的图片时，我们并不会注意图片中的每个细节，而是在每个区域选出有代表性特征，然后组合这些特征形成一个更小更利于理解的特征图。使用池化可以大大降低特征图的大小，并且减少过拟合现象。 上图描述了一个典型的池化操作，将这个特征图分为四个部分，每个部分取出一个代表性特征，并最终形成一个4X4的池化特征图。 和卷积一样，池化也有几个需要考虑参数： Size：每次池化的范围 Stride：池化范围在特征图移动的距离 上图就是一个典型的Size=Stride的池化。 池化方法 平均池化：Size=Stride，取池化范围中所有的值的均值作为特征 最大池化：Size=Stride，取池化范围中的最大值作为特征 重叠池化：Stride&lt;Size，此时池化范围会有重叠，包含重叠平均池化和重叠最大池化。 2.5.2. 失活 Dropout一个降低预测误差的方法是，我们训练多个不同的模型，并且将这些模型的预测结果结合起来。这是一个很好的想法，但是代价也相当的大。训练一个模型已经需要相当长的时间，训练多个模型的成本将成倍增加，但是收益却并没有那么显著。因此一个折中的方案被提出————失活。 失活这个机制在神经网络中作用的方式是，对于每次输入，隐藏层中的每个神经元的输出都有一定的概率（例如0.5）被设为0，这些失活的神经元不再参与前向传播和反向传播。因此，每次输入，神经网络都会以一种不同的结构，这强迫神经元学习更加鲁棒的特征，减少相互之间的依赖，以适应随机的失活机制。 在实践中，失活机制大大减少了过拟合的现象，代价则是使得收敛的时间翻了一倍。 2.6. 局部响应归一化 Local Response Normalization局部响应归一化原理是仿造生物学上活跃的神经细胞对相邻神经细胞的抑制现象（侧抑制）。它将神经网络中响应较强的特征到增强，而响应较弱的特征被抑制，从而加快收敛速度。 其公式如下： $$b_{x,y}^i=a_{x,y}^i/\left(k+\alpha\sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a_{x,y}^j)^2\right)^\beta$$ 其中$a_{x,y}^i$表示在i通道中的，x、y位置上的点的值，k、$\alpha$、$\beta$、n都是自定义的值。 从上图我们可以得知，实际上是以$a_{x,y}^i$为中心，沿着通道的轴的方向取n个值累加值作为分母，若该点的值越大，则被加强的越多；若越小，则被抑制的越多。 2.7. SoftMax它能将一个含任意实数的K维的向量$z$的“压缩”到另一个K维实向量$\sigma(z)中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1。该函数的形式通常按下面的式子给出： $$\sigma(z)_j=\frac{e^{z_j}}{\sum_{k=1}^Ke^{z_k}}$$ 假设神经网络最后的全连接输出的向量为1000维，那么将这1000维的向量输入SoftMax函数中，将会输出1000维的概率向量。这个向量中的每一个值描述了这个输入属于1000个分类中每个分类的概率。 3. 参考图片来自Google Image Krizhevsky A, Sutskever I, Hinton G E. ImageNet Classification with Deep Convolutional Neural Networks 维基百科. 前馈神经网络 维基百科. 感知器 UFLDL教程 维基百科. 链式法则 维基百科. 反向传播算法 Charlotte77. 一文弄懂神经网络中的反向传播法——BackPropagation 维基百科. 线性整流函数 维基百科. 过拟合]]></content>
      <categories>
        <category>Homework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[树莓派系统安装与配置]]></title>
    <url>%2Fposts%2F159d%2F</url>
    <content type="text"><![CDATA[本文涉及到树莓派系统安装，SSH登录，镜像加速配置，无线网卡配置，挂载NTFS硬盘。 一、写入系统由于没有多余的显示屏可以使用，所以只能盲装系统。系统可以从这里下载，由于没有显示器，所以我选择了以下版本 Windows下烧录系统还需要win32diskimager插上SD卡，在Win32DiskImager中选择下载的系统镜像和设备，写入。 写入成功后，在盘符为boot的U盘根目录下，创建一个名为ssh的空文件。这是因为新版本的Raspbian默认不开启ssh，可以通过这个方式让其打开ssh功能。 将SD卡插入树莓派，连上网线和电源。 二、SSH登录树莓派首先需要获取树莓派在内网的地址，这里通过路由器来查看。 使用SSH登录树莓派，账户pi，密码raspberry1ssh pi@192.168.0.103 三、配置镜像加速国外的apt-get源实在是太慢了，这替换成清华大学Raspbian镜像1sudo nano /etc/apt/sources.list 将/etc/apt/sources.list的内容替换为12deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ jessie main non-free contribdeb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ jessie main non-free contrib 然后运行sudo apt-get update 四、配置无线网卡1ifconfig wlan0 可以看到树莓派已经成功挂载无线网卡 修改配置/etc/network/interfaces12345678910111213source-directory /etc/network/interfaces.dauto lo wlan0 wlan1iface lo inet loopbackiface eth0 inet dhcpallow-hotplug wlan0 wlan1iface wlan0 inet dhcpwpa-conf /etc/wpa_supplicant/wpa_supplicant.confiface wlan1 inet manual 修改配置/etc/wpa_supplicant/wpa_supplicant.conf注意 priority 高的wifi将被优先连接123456789101112131415country=GBctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1network=&#123; ssid=&quot;WIFI名1&quot; psk=&quot;WIFI密码1&quot; priority=2&#125;network=&#123; ssid=&quot;WIFI名2&quot; psk=&quot;WIFI密码2&quot; priority=1&#125; 运行命令sudo ifup wlan0 红色部分则为wifi链接的ip 五、挂载硬盘由于我的移动硬盘是NTFS格式，所以需要下载对应的驱动1sudo apt-get install ntfs-3g 将移动硬盘连接到树莓派，使用sudo fdisk -l查看磁盘状况 在/dev/sda1发现移动硬盘，这里sda1取决于你的情况，a表示第一个硬盘，1表示第一个分区 创建文件夹并挂载磁盘12sudo mkdir /mnt/usbsudo mount -o uid=pi,gid=pi /dev/sda1 /mnt/usb 卸载磁盘方法1sudo umount /mnt/usb]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
  </entry>
</search>
